{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc71cf6-4791-4e52-ba7a-a2c34d3e10a7",
   "metadata": {},
   "source": [
    "\n",
    "**获取数据集信息**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37bb0fa5-f9c7-48db-a456-948929308331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'Xtest', 'ytest', 'X', 'y', 'Xvalid', 'yvalid'])\n",
      "Xtest_shape:(1000, 256)\n",
      "ytest_shape:(1000, 1)\n",
      "X_shape:(5000, 256)\n",
      "y_shape:(5000, 1)\n",
      "Xvalid_shape:(5000, 256)\n",
      "yvalid_shape:(5000, 1)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat('/Users/lvangge/Desktop/Archive/project1_release/codes/digits.mat')\n",
    "\n",
    "print(data.keys())\n",
    "\n",
    "# 获取特定变量的值\n",
    "for i in data.keys():\n",
    "    try:\n",
    "        print(f\"{i}_shape:{data[i].shape}\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c336d-6fb9-4875-8311-97dda8324a06",
   "metadata": {},
   "source": [
    "\n",
    "**查看加载其中一张图片**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f04abd0-6858-46d0-95a2-5dc7a9dabb1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  29  85   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 135 208   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  4 212 224   0   0   0   0   0   0   0   0   0   0  45   4   0]\n",
      " [  8 241 158   0   0   0   0  33  98   0   0   0  75 249 146   3]\n",
      " [108 255 142   0   0   0  14 248 255  70   0   8 148 249 255  24]\n",
      " [173 255 142   0   0   0 138 255 250  42   0  42 104  95 255  90]\n",
      " [173 255  93   0   0 103 247 255 113   0   0   0   0  63 255 139]\n",
      " [173 255  61   0 140 249 255 255  80   0   0   0   0  13 241 171]\n",
      " [173 255  61 107 255 255 255 255  97   0   0   0  11 167 255 106]\n",
      " [140 255 151 245 255 197 214 255 162   0   0   0 151 255 225   5]\n",
      " [ 92 255 255 255 207  12 137 255 162   0   0 108 255 255  83   0]\n",
      " [ 92 255 255 238  40   0  72 255 162   0  59 245 255 171   4   0]\n",
      " [  8 241 249  73   0   0  29 250 214  61 199 255 207  12   0   0]\n",
      " [  0  77  68   0   0   0   0 213 255 255 255 255  88   0   0   0]\n",
      " [  0   0   0   0   0   0   0  98 255 255 248 137   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  87 152 100   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAGdCAYAAADtxiFiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuQ0lEQVR4nO3dfXRU5bn+8WtIyCRgEgyal6kJRI+VVwEFYoRaKFmEiChLWosnQoouqW2CQjyI8QgqKCmWo4hNQWwFPSW+HkHltGgMCHrkNTEqqBFsClE6SauSgSAhJPP7wx9TRwLJkNmZPOzvZ629lrNn59431PTyfvbM3g6v1+sVAAAwSpdQNwAAAAJHgAMAYCACHAAAAxHgAAAYiAAHAMBABDgAAAYiwAEAMBABDgCAgcJD3cD3NTc368CBA4qOjpbD4Qh1OwCAAHm9Xh06dEgul0tdulg3Jx49elTHjh1rd52IiAhFRkYGoaOO1ekC/MCBA0pOTg51GwCAdqqurtYFF1xgSe2jR48qNTVVbre73bUSExNVVVVlXIh3ugCPjo62tP4PfvADy2oPGzbMstpr1661rDYAWMHK/z8/duyY3G639u/fr5iYmDOu4/F4lJKSomPHjhHg7WX1srmVyzldu3a1rDYAmKYjLoPGxMS0K8BNxofYAADG8nq97d4CUVhYqGHDhik6Olrx8fGaOHGiKisr/Y4ZNWqUHA6H33bbbbf5HbN//36NHz9e3bp1U3x8vGbPnq3jx48H1Eunm8ABAGirMwnh7/98IDZt2qTc3FwNGzZMx48f1z333KOxY8fqo48+Uvfu3X3H3XrrrZo/f77vdbdu3Xz/3NTUpPHjxysxMVHvvvuu/v73v2vq1Knq2rWrFi5c2OZeCHAAgLE6OsDXr1/v93rVqlWKj49XWVmZrrrqKt/+bt26KTExscUab7zxhj766CO9+eabSkhI0ODBg7VgwQLNmTNH999/vyIiItrUC0voAADb83g8fltDQ0Obfq6urk6SFBcX57d/9erVOu+88zRgwAAVFBToyJEjvve2bNmigQMHKiEhwbcvMzNTHo9Hu3fvbnPPlgV4UVGRevfurcjISKWlpWn79u1WnQoAYFPBugaenJys2NhY31ZYWNjquZubmzVz5kyNGDFCAwYM8O3/93//d/3pT3/Sxo0bVVBQoP/+7//WTTfd5Hvf7Xb7hbck3+tAvhZnyRL6888/r/z8fC1fvlxpaWlasmSJMjMzVVlZqfj4eCtOCQCwoWAtoVdXV/t9mt3pdLb6s7m5udq1a5feeecdv/3Tp0/3/fPAgQOVlJSkMWPG6LPPPtNFF110xr1+nyUT+COPPKJbb71V06ZNU79+/bR8+XJ169ZNTz31lBWnAwCgXU58He3E1lqA5+Xlad26ddq4cWOrN6tJS0uTJO3du1fStzeOqamp8TvmxOtTXTdvSdAD/NixYyorK1NGRsa/TtKlizIyMrRly5aTjm9oaDjp2gMAAG3R0V8j83q9ysvL05o1a7Rhwwalpqa2+jMVFRWSpKSkJElSenq6PvzwQ9XW1vqOKSkpUUxMjPr169fmXoIe4P/85z/V1NTU4vp+S2v7hYWFftcduI0qAKCtOjrAc3Nz9ac//UnFxcWKjo6W2+2W2+3WN998I0n67LPPtGDBApWVlelvf/ubXn31VU2dOlVXXXWVLr30UknS2LFj1a9fP02ZMkXvv/++Xn/9dd17773Kzc1t09L9CSH/FHpBQYHq6up8W3V1dahbAgCgRcuWLVNdXZ1GjRqlpKQk3/b8889L+vbBKG+++abGjh2rPn366M4779SkSZP02muv+WqEhYVp3bp1CgsLU3p6um666SZNnTrV73vjbRH0D7Gdd955CgsLa3F9v6W1fafTGdB/cQAAcEJHfw+8teOTk5O1adOmVuv06tVLf/7znwM69/cFfQKPiIjQ5ZdfrtLSUt++5uZmlZaWKj09PdinAwDYWEcvoXcmlnyNLD8/Xzk5ORo6dKiGDx+uJUuWqL6+XtOmTbPidAAA2I4lAf7zn/9c//jHPzRv3jy53W4NHjxY69evP+mDbQAAtEdHL6F3JpbdCz0vL095eXlWlQcAgAAHAMBEdg7wkH+NDAAABI4JHABgLDtP4AQ4AMBYBLiN/PrXv7asdlZWlmW1X3zxRctqAwDMY7sABwCcPZjAAQAwkJ0DnE+hAwBgICZwAICx7DyBE+AAAKOZHMLtwRI6AAAGYgIHABiLJXQAAAxEgAMAYCA7BzjXwAEAMBATOADAWHaewAlwAICx7BzgLKEDAGAgJnAAgLHsPIET4AAAY9k5wFlCBwDAQEzgAABj2XkCJ8ABAMayc4CzhA4AgIGYwAEAxrLzBE6AAwCMRYADAGAgArwTCgsLk8PhCHrda665Jug1T4iOjrasNoDOa8CAAZbV/uSTTyyrffz4cctqw3qdNsABAGgNEzgAAAayc4DzNTIAAAzEBA4AMJadJ3ACHABgLDsHOEvoAAAYiAkcAGAsJvAgKiws1LBhwxQdHa34+HhNnDhRlZWVwT4NAACS/hXiZ7KZLOgBvmnTJuXm5mrr1q0qKSlRY2Ojxo4dq/r6+mCfCgAA2wr6Evr69ev9Xq9atUrx8fEqKyvTVVddFezTAQBszM5L6JZfA6+rq5MkxcXFtfh+Q0ODGhoafK89Ho/VLQEAzhJ2DnBLP4Xe3NysmTNnasSIEae8V3BhYaFiY2N9W3JyspUtAQDOIu25/m36dXBLAzw3N1e7du3Sc889d8pjCgoKVFdX59uqq6utbAkAgLOCZUvoeXl5WrdunTZv3qwLLrjglMc5nU45nU6r2gAAnMXsvIQe9AD3er2aMWOG1qxZo7feekupqanBPgUAAJII8KDKzc1VcXGxXnnlFUVHR8vtdkuSYmNjFRUVFezTAQBgS0G/Br5s2TLV1dVp1KhRSkpK8m3PP/98sE8FALA5O3+IzZIldAAAOoKdl9B5mAkAAAbiYSYAAGPZeQInwAEAxrJzgLOEDgCAgTrtBB4eHi6HwxH0uikpKUGvecL//M//WFYbHa93796W1R49erRltVeuXGlZbVONHz/e0vovv/yyZbWfeOIJy2rPmjXLkrper1fNzc2W1G7pXHadwDttgAMA0BoCHAAAA9k5wLkGDgCAgZjAAQDGsvMEToADAIxl5wBnCR0AAAMR4AAAY3X0w0wKCws1bNgwRUdHKz4+XhMnTlRlZaXfMUePHlVubq569uypc845R5MmTVJNTY3fMfv379f48ePVrVs3xcfHa/bs2Tp+/HhAvRDgAABjdXSAb9q0Sbm5udq6datKSkrU2NiosWPHqr6+3nfMrFmz9Nprr+nFF1/Upk2bdODAAV1//fW+95uamjR+/HgdO3ZM7777rp5++mmtWrVK8+bNC6gXroEDANBG69ev93u9atUqxcfHq6ysTFdddZXq6ur0xz/+UcXFxfrJT34i6dubK/Xt21dbt27VFVdcoTfeeEMfffSR3nzzTSUkJGjw4MFasGCB5syZo/vvv18RERFt6oUJHABgrGBN4B6Px29raGho0/nr6uokSXFxcZKksrIyNTY2KiMjw3dMnz59lJKSoi1btkiStmzZooEDByohIcF3TGZmpjwej3bv3t3mPzsBDgAwWjCWz5OTkxUbG+vbCgsLWz1vc3OzZs6cqREjRmjAgAGSJLfbrYiICPXo0cPv2ISEBLndbt8x3w3vE++feK+tWEIHANhedXW1YmJifK+dTmerP5Obm6tdu3bpnXfesbK1UyLAAQDGCtb3wGNiYvwCvDV5eXlat26dNm/erAsuuMC3PzExUceOHdPBgwf9pvCamholJib6jtm+fbtfvROfUj9xTFuwhA4AMFZHfwrd6/UqLy9Pa9as0YYNG5Samur3/uWXX66uXbuqtLTUt6+yslL79+9Xenq6JCk9PV0ffvihamtrfceUlJQoJiZG/fr1a3MvTOAAAGN19J3YcnNzVVxcrFdeeUXR0dG+a9axsbGKiopSbGysbrnlFuXn5ysuLk4xMTGaMWOG0tPTdcUVV0iSxo4dq379+mnKlCl6+OGH5Xa7de+99yo3N7dNS/cnEOAAALTRsmXLJEmjRo3y279y5Ur94he/kCQ9+uij6tKliyZNmqSGhgZlZmbq97//ve/YsLAwrVu3Tr/61a+Unp6u7t27KycnR/Pnzw+oFwIcAGCsjp7A23J8ZGSkioqKVFRUdMpjevXqpT//+c8Bnfv7CHAAgLF4mAkAADAKEzgAwFh2nsAJcACAsewc4CyhAwBgoE47gefk5LT5iSyBCOROO4E6ePCgZbXRMiv/9/zkk08sqx3Idz0D9cUXX1hW+4033rCsdmRkpGW1x40bZ1ltq82YMcOy2gsXLrSkbnNzs99NSqxk5wm80wY4AACtsXOAs4QOAICBmMABAMay8wROgAMAjEWAAwBgIDsHONfAAQAwEBM4AMBYTOAW+s1vfiOHw6GZM2dafSoAgM2cCPD2bKayNMB37NihJ554QpdeeqmVpwEAwHYsC/DDhw8rOztbTz75pM4991yrTgMAsDEmcAvk5uZq/PjxysjIsOoUAACbs3OAW/Ihtueee07l5eXasWNHq8c2NDSooaHB99rj8VjREgAAZ5WgT+DV1dW64447tHr16jY9nKCwsFCxsbG+LTk5OdgtAQDOUnaewIMe4GVlZaqtrdVll12m8PBwhYeHa9OmTVq6dKnCw8PV1NTkd3xBQYHq6up8W3V1dbBbAgCcxewY3pIFS+hjxozRhx9+6Ldv2rRp6tOnj+bMmaOwsDC/95xOp6WPVgQA4GwU9ACPjo7WgAED/PZ1795dPXv2PGk/AADtYecbuXAnNgCAsQhwi7311lsdcRoAgM3YOcB5mAkAAAZiCR0AYCw7T+AEOADAWHYOcJbQAQAwEBM4AMBYdp7AO22A/+hHP1K3bt1C3QY6uXvvvdey2lbeYKixsdGy2p9//rllta104YUXWlZ79+7dltWWpOnTp1tWe9WqVZbVHj16tCV1Gxsb9dJLL1lS+/vsHOAsoQMAYKBOO4EDANAaO0/gBDgAwFh2DnCW0AEAMBATOADAWHaewAlwAICxCHAAAAxk5wDnGjgAAAZiAgcAGMvOEzgBDgAwlp0DnCV0AAAMxAQOADCWnSdwAhwAYCw7BzhL6AAAGIgJHABgLDtP4AQ4AMBYdg5wltABADAQEzgAwGgmT9HtQYADAIxl5yV0AhwAYCw7BzjXwAEAMBATOADAWHaewAnwIHrvvfdC3UKn9Mtf/tKy2jNmzLCstpXmzJljWe2PPvrIstpWsrJvq/9OfvzjH1ta3yqXXXaZJXWPHj2ql156yZLa32fnAGcJHQAAAzGBAwCMZecJnAAHABjLzgHOEjoAAAZiAgcAGMvOEzgBDgAwFgEOAICB7BzgllwD/+KLL3TTTTepZ8+eioqK0sCBA7Vz504rTgUAgC0FfQL/+uuvNWLECI0ePVp/+ctfdP7552vPnj0699xzg30qAIDNMYEH0aJFi5ScnKyVK1dq+PDhSk1N1dixY3XRRRcF+1QAAJs7EeDt2QK1efNmTZgwQS6XSw6HQ2vXrvV7/xe/+IUcDoffNm7cOL9jvvrqK2VnZysmJkY9evTQLbfcosOHDwfUR9AD/NVXX9XQoUP1s5/9TPHx8RoyZIiefPLJUx7f0NAgj8fjtwEA0FnV19dr0KBBKioqOuUx48aN09///nff9uyzz/q9n52drd27d6ukpETr1q3T5s2bNX369ID6CPoS+l//+lctW7ZM+fn5uueee7Rjxw7dfvvtioiIUE5OzknHFxYW6oEHHgh2GwAAGwjFEnpWVpaysrJOe4zT6VRiYmKL73388cdav369duzYoaFDh0qSHn/8cV199dVavHixXC5Xm/oI+gTe3Nysyy67TAsXLtSQIUM0ffp03XrrrVq+fHmLxxcUFKiurs63VVdXB7slAMBZKlhL6N9fCW5oaGhXX2+99Zbi4+N1ySWX6Fe/+pW+/PJL33tbtmxRjx49fOEtSRkZGerSpYu2bdvW5nMEPcCTkpLUr18/v319+/bV/v37Wzze6XQqJibGbwMAoCMlJycrNjbWtxUWFp5xrXHjxumZZ55RaWmpFi1apE2bNikrK0tNTU2SJLfbrfj4eL+fCQ8PV1xcnNxud5vPE/Ql9BEjRqiystJv36effqpevXoF+1QAAJsL1hJ6dXW13wDpdDrPuObkyZN9/zxw4EBdeumluuiii/TWW29pzJgxZ1z3+4I+gc+aNUtbt27VwoULtXfvXhUXF2vFihXKzc0N9qkAADYXrCX0768EtyfAv+/CCy/Ueeedp71790qSEhMTVVtb63fM8ePH9dVXX53yunlLgh7gw4YN05o1a/Tss89qwIABWrBggZYsWaLs7OxgnwoAgE7v888/15dffqmkpCRJUnp6ug4ePKiysjLfMRs2bFBzc7PS0tLaXNeSW6lec801uuaaa6woDQCATyg+hX748GHfNC1JVVVVqqioUFxcnOLi4vTAAw9o0qRJSkxM1Geffaa77rpL//Zv/6bMzExJ334ubNy4cb4PeDc2NiovL0+TJ09u8yfQJR4nCgAwWChu5LJz504NGTJEQ4YMkSTl5+dryJAhmjdvnsLCwvTBBx/o2muv1Q9/+EPdcsstuvzyy/X222/7LcuvXr1affr00ZgxY3T11Vdr5MiRWrFiRUB98DATAIDROvp2qKNGjTrtOV9//fVWa8TFxam4uLhdfTCBAwBgICZwAICx7PwwEwI8iKqqqkLdwhlZvHixpfVnzJhhWe2IiAjLalvJ1H9X0LLy8nLLalv5fIjevXtbUvfIkSOW1G2JnQOcJXQAAAzEBA4AMJadJ3ACHABgLDsHOEvoAAAYiAkcAGAsO0/gBDgAwFh2DnCW0AEAMBATOADAWHaewAlwAICxCHAAAAxk5wDnGjgAAAZiAgcAGMvOEzgBDgAwlp0DnCV0AAAMxAQOADCWnSdwAhwAYCw7BzhL6AAAGIgJHABgLDtP4AQ4AMBYdg5wltABADAQEzgAwFh2nsAJcACAsQhwdHq5ubmW1b7zzjstq42WnXvuuaFuwVa6d+9uaf0VK1ZYVjsmJsay2hs2bLCk7rFjxyypeyomh3B7cA0cAAADMYEDAIzFEjoAAAayc4CzhA4AgIGYwAEAxrLzBE6AAwCMZecAZwkdAAADBT3Am5qaNHfuXKWmpioqKkoXXXSRFixYYPR/5QAAOqcTE3h7NlMFfQl90aJFWrZsmZ5++mn1799fO3fu1LRp0xQbG6vbb7892KcDANiYnZfQgx7g7777rq677jqNHz9ektS7d289++yz2r59e7BPBQCAbQV9Cf3KK69UaWmpPv30U0nS+++/r3feeUdZWVktHt/Q0CCPx+O3AQDQFiyhB9Hdd98tj8ejPn36KCwsTE1NTXrooYeUnZ3d4vGFhYV64IEHgt0GAMAG7LyEHvQJ/IUXXtDq1atVXFys8vJyPf3001q8eLGefvrpFo8vKChQXV2db6uurg52SwCAsxQTeBDNnj1bd999tyZPnixJGjhwoPbt26fCwkLl5OScdLzT6ZTT6Qx2GwAAnNWCHuBHjhxRly7+g31YWJiam5uDfSoAgM3ZeQk96AE+YcIEPfTQQ0pJSVH//v313nvv6ZFHHtHNN98c7FMBAGyOAA+ixx9/XHPnztWvf/1r1dbWyuVy6Ze//KXmzZsX7FMBAGBbQQ/w6OhoLVmyREuWLAl2aQAA/DCBAwBgIDsHOA8zAQDAQEzgAABj2XkCJ8ABAMYiwDuhffv2KTIyMtRtBORUt4sNhqlTp1pW22rvvvuuZbXPPfdcy2r37dvXstqjR4+2rPbKlSstq22qxYsXW1r/xI2rrLB//37Lav/hD3+wpK7JoWiSThvgAAC0hgkcAAADEeAAABjK5BBuD75GBgCAgZjAAQDGYgkdAAAD2TnAWUIHAMBATOAAAGPZeQInwAEAxrJzgLOEDgCAgZjAAQDGsvMEToADAIxl5wBnCR0AgABs3rxZEyZMkMvlksPh0Nq1a/3e93q9mjdvnpKSkhQVFaWMjAzt2bPH75ivvvpK2dnZiomJUY8ePXTLLbfo8OHDAfVBgAMAjHViAm/PFqj6+noNGjRIRUVFLb7/8MMPa+nSpVq+fLm2bdum7t27KzMzU0ePHvUdk52drd27d6ukpETr1q3T5s2bNX369ID6YAkdAGCsUCyhZ2VlKSsr65T1lixZonvvvVfXXXedJOmZZ55RQkKC1q5dq8mTJ+vjjz/W+vXrtWPHDg0dOlSS9Pjjj+vqq6/W4sWL5XK52tQHEzgAwFjBmsA9Ho/f1tDQcEb9VFVVye12KyMjw7cvNjZWaWlp2rJliyRpy5Yt6tGjhy+8JSkjI0NdunTRtm3b2nwuAhwAYHvJycmKjY31bYWFhWdUx+12S5ISEhL89ickJPjec7vdio+P93s/PDxccXFxvmPagiV0AICxgrWEXl1drZiYGN9+p9PZ7t6sxgQOADBWsJbQY2Ji/LYzDfDExERJUk1Njd/+mpoa33uJiYmqra31e//48eP66quvfMe0BQEOAECQpKamKjExUaWlpb59Ho9H27ZtU3p6uiQpPT1dBw8eVFlZme+YDRs2qLm5WWlpaW0+F0voAABjheJT6IcPH9bevXt9r6uqqlRRUaG4uDilpKRo5syZevDBB3XxxRcrNTVVc+fOlcvl0sSJEyVJffv21bhx43Trrbdq+fLlamxsVF5eniZPntzmT6BLBDgAwGChCPCdO3dq9OjRvtf5+fmSpJycHK1atUp33XWX6uvrNX36dB08eFAjR47U+vXrFRkZ6fuZ1atXKy8vT2PGjFGXLl00adIkLV26NKA+Om2Af/DBB4qIiAh1GwG57bbbQt3CGamoqLC0fmZmpmW1586da1ntvn37WlYbJ8vLy7Ostqm/m9K/wsEKjY2NltU+m40aNeq0we9wODR//nzNnz//lMfExcWpuLi4XX102gAHAKA1dr4XOgEOADCWnQOcT6EDAGAgJnAAgLHsPIET4AAAYxHgAAAYyuQQbg+ugQMAYKCAA3zz5s2aMGGCXC6XHA6H1q5d6/e+1+vVvHnzlJSUpKioKGVkZGjPnj3B6hcAAJ9g3QvdRAEHeH19vQYNGqSioqIW33/44Ye1dOlSLV++XNu2bVP37t2VmZmpo0ePtrtZAAC+y84BHvA18KysLGVlZbX4ntfr1ZIlS3TvvffquuuukyQ988wzSkhI0Nq1azV58uT2dQsAACQF+Rp4VVWV3G63MjIyfPtiY2OVlpamLVu2tPgzDQ0N8ng8fhsAAG1h5wk8qAHudrslSQkJCX77ExISfO99X2FhoWJjY31bcnJyMFsCAJzFCPAQKigoUF1dnW+rrq4OdUsAAHR6Qf0eeGJioiSppqZGSUlJvv01NTUaPHhwiz/jdDrldDqD2QYAwCbsfCOXoE7gqampSkxMVGlpqW+fx+PRtm3blJ6eHsxTAQBg6yX0gCfww4cPa+/evb7XVVVVqqioUFxcnFJSUjRz5kw9+OCDuvjii5Wamqq5c+fK5XJp4sSJwewbAABbCzjAd+7cqdGjR/ten3jYfE5OjlatWqW77rpL9fX1mj59ug4ePKiRI0dq/fr1ioyMDF7XAADI3kvoAQf4qFGjTvsHdjgcmj9/vubPn9+uxgAAaA0BDgCAgewc4CH/GhkAAAgcEzgAwFh2nsAJcACAsQhwdHpff/21ZbVvvPFGy2pL33710CobN260rPZdd91lWW1TjRgxwrLaixYtsqy21V566SXLar/yyiuW1YbZCHAAgLGYwAEAMJCdA5xPoQMAYCAmcACAsew8gRPgAABj2TnAWUIHAMBATOAAAGPZeQInwAEAxiLAAQAwkJ0DnGvgAAAYiAkcAGA0k6fo9iDAAQDGYgkdAAAYhQkcAGAsO0/gBDgAwFh2DnCW0AEAMBATOADAWHaewAlwAICx7BzgLKEDAGAgJnAAgLHsPIET4AAAYxHgAAAYiADvhF555RU5HI6g1y0qKgp6zRMiIyMtq52dnW1Z7U8++cSy2lbbvXu3ZbUbGxstqz106FDLao8cOdKy2r/97W8tq92tWzfLaldUVFhWW5KmTZtmWe3jx49bVhtm67QBDgBAa5jAAQAwkJ0DnK+RAQBgICZwAICx7DyBE+AAAGPZOcBZQgcAwEBM4AAAYzGBB2Dz5s2aMGGCXC6XHA6H1q5d63uvsbFRc+bM0cCBA9W9e3e5XC5NnTpVBw4cCGbPAABI+leAt2czVcABXl9fr0GDBrV4Q5QjR46ovLxcc+fOVXl5uV5++WVVVlbq2muvDUqzAADgWwEvoWdlZSkrK6vF92JjY1VSUuK373e/+52GDx+u/fv3KyUl5cy6BACgBXZeQrf8GnhdXZ0cDod69OjR4vsNDQ1qaGjwvfZ4PFa3BAA4S9g5wC39FPrRo0c1Z84c3XjjjYqJiWnxmMLCQsXGxvq25ORkK1sCAJxFuAZugcbGRt1www3yer1atmzZKY8rKChQXV2db6uurraqJQAAzhqWLKGfCO99+/Zpw4YNp5y+JcnpdMrpdFrRBgDABkyeotsj6AF+Irz37NmjjRs3qmfPnsE+BQAAkux9DTzgAD98+LD27t3re11VVaWKigrFxcUpKSlJP/3pT1VeXq5169apqalJbrdbkhQXF6eIiIjgdQ4AgI0FfA18586dGjJkiIYMGSJJys/P15AhQzRv3jx98cUXevXVV/X5559r8ODBSkpK8m3vvvtu0JsHANhbR3+I7f7775fD4fDb+vTp43v/6NGjys3NVc+ePXXOOedo0qRJqqmpCfYfW9IZTOCjRo067R/Y5OUIAIBZQrGE3r9/f7355pu+1+Hh/4rSWbNm6X//93/14osvKjY2Vnl5ebr++uv1f//3f2fc46lwL3QAAAIQHh6uxMTEk/bX1dXpj3/8o4qLi/WTn/xEkrRy5Ur17dtXW7du1RVXXBHUPngaGQDAWMFaQvd4PH7bd28w9n179uyRy+XShRdeqOzsbO3fv1+SVFZWpsbGRmVkZPiO7dOnj1JSUrRly5ag/9kJcACAsYIV4MnJyX43FSssLGzxfGlpaVq1apXWr1+vZcuWqaqqSj/60Y906NAhud1uRUREnHTn0YSEBN8HuoOJJXQAgO1VV1f73bPkVPcn+e6zQC699FKlpaWpV69eeuGFFxQVFWV5n9/FBA4AMFawJvCYmBi/ra03GOvRo4d++MMfau/evUpMTNSxY8d08OBBv2NqampavGbeXp12Aj/d9Yf2uOmmmyypK0nffPONZbW/+4lH/IuVt97ds2ePZbX79etnWe23337bstqmWrRokaX1Dx8+bGl9nFqob+Ry+PBhffbZZ5oyZYouv/xyde3aVaWlpZo0aZIkqbKyUvv371d6enq7ztOSThvgAAC0pqMD/D/+4z80YcIE9erVSwcOHNB9992nsLAw3XjjjYqNjdUtt9yi/Px8xcXFKSYmRjNmzFB6enrQP4EuEeAAALTZ559/rhtvvFFffvmlzj//fI0cOVJbt27V+eefL0l69NFH1aVLF02aNEkNDQ3KzMzU73//e0t6IcABAMbq6An8ueeeO+37kZGRKioqUlFR0Rn31FYEOADAWKG+Bh5KfAodAAADMYEDAIxl5wmcAAcAGMvOAc4SOgAABmICBwAYy84TOAEOADCWnQOcJXQAAAzEBA4AMJadJ3ACHABgLAIcAAAD2TnAuQYOAICBmMABAEYzeYpuDwIcAGAsltABAIBRmMABAMay8wROgAMAjGXnAGcJHQAAAzGBAwCMZecJ3HYB/tprr4W6BRhi8eLFltV+6qmnLKttpYaGBstqP/bYY5bVfu655yyrjdCyc4CzhA4AgIFsN4EDAM4edp7ACXAAgLEIcAAADGTnAOcaOAAABmICBwAYiwk8AJs3b9aECRPkcrnkcDi0du3aUx572223yeFwaMmSJe1oEQCAlp0I8PZspgo4wOvr6zVo0CAVFRWd9rg1a9Zo69atcrlcZ9wcAABoWcBL6FlZWcrKyjrtMV988YVmzJih119/XePHjz/j5gAAOB07L6EH/Rp4c3OzpkyZotmzZ6t///7BLg8AgA8BHkSLFi1SeHi4br/99jYd39DQ4Hd7Ro/HE+yWAAA46wQ1wMvKyvTYY4+pvLxcDoejTT9TWFioBx54IJhtAABsws4TeFC/B/7222+rtrZWKSkpCg8PV3h4uPbt26c777xTvXv3bvFnCgoKVFdX59uqq6uD2RIA4Cxm50+hB3UCnzJlijIyMvz2ZWZmasqUKZo2bVqLP+N0OuV0OoPZBgAAZ72AA/zw4cPau3ev73VVVZUqKioUFxenlJQU9ezZ0+/4rl27KjExUZdcckn7uwUA4DvsvIQecIDv3LlTo0eP9r3Oz8+XJOXk5GjVqlVBawwAgNYQ4AEYNWpUQH/gv/3tb4GeAgCANrFzgPMwEwAADMTDTAAARjN5im4PAhwAYKz2hrfJ4c8SOgAABmICBwAYy84TOAEOnMLKlSstq33kyBHLan/3a57BtnPnTstq/+EPf7CsNs5edg5wltABADAQEzgAwFh2nsAJcACAsewc4CyhAwBgICZwAICx7DyBE+AAAGMR4AAAGMjOAc41cAAADMQEDgAwlp0ncAIcAGAsOwc4S+gAABiICRwAYCw7T+AEOADAWHYOcJbQAQAwEBM4AMBYdp7ACXAAgLHsHOAsoQMAYCAmcACAsZjAAQAwkNfrbfd2JoqKitS7d29FRkYqLS1N27dvD/KfrHUEOADAWKEI8Oeff175+fm67777VF5erkGDBikzM1O1tbUW/AlPjQAHACAAjzzyiG699VZNmzZN/fr10/Lly9WtWzc99dRTHdpHp7sGbvL1CKCtGhsbLav9zTffWFb72LFjltXG2aej/v88GOfxeDx+r51Op5xO50nHHTt2TGVlZSooKPDt69KlizIyMrRly5Z29xGIThfghw4dCnULgOVefvllI2sDgTh06JBiY2MtqR0REaHExES53e521zrnnHOUnJzst+++++7T/ffff9Kx//znP9XU1KSEhAS//QkJCfrkk0/a3UsgOl2Au1wuVVdXKzo6Wg6Ho9XjPR6PkpOTVV1drZiYmA7oMDjou2OZ2rdkbu/03bE6U99er1eHDh2Sy+Wy7ByRkZGqqqoKyqqQ1+s9KW9amr47m04X4F26dNEFF1wQ8M/FxMSE/F/aM0HfHcvUviVze6fvjtVZ+rZq8v6uyMhIRUZGWn6e7zrvvPMUFhammpoav/01NTVKTEzs0F74EBsAAG0UERGhyy+/XKWlpb59zc3NKi0tVXp6eof20ukmcAAAOrP8/Hzl5ORo6NChGj58uJYsWaL6+npNmzatQ/swPsCdTqfuu+8+I65XfBd9dyxT+5bM7Z2+O5apfZvo5z//uf7xj39o3rx5crvdGjx4sNavX3/SB9us5vDyvS0AAIzDNXAAAAxEgAMAYCACHAAAAxHgAAAYyOgA7wyPcwtUYWGhhg0bpujoaMXHx2vixImqrKwMdVsB+81vfiOHw6GZM2eGupVWffHFF7rpppvUs2dPRUVFaeDAgdq5c2eo2zqtpqYmzZ07V6mpqYqKitJFF12kBQsWdMpnBWzevFkTJkyQy+WSw+HQ2rVr/d73er2aN2+ekpKSFBUVpYyMDO3Zsyc0zX7H6fpubGzUnDlzNHDgQHXv3l0ul0tTp07VgQMHQtfw/9fa3/d33XbbbXI4HFqyZEmH9YeOY2yAd5bHuQVq06ZNys3N1datW1VSUqLGxkaNHTtW9fX1oW6tzXbs2KEnnnhCl156aahbadXXX3+tESNGqGvXrvrLX/6ijz76SP/1X/+lc889N9StndaiRYu0bNky/e53v9PHH3+sRYsW6eGHH9bjjz8e6tZOUl9fr0GDBqmoqKjF9x9++GEtXbpUy5cv17Zt29S9e3dlZmbq6NGjHdypv9P1feTIEZWXl2vu3LkqLy/Xyy+/rMrKSl177bUh6NRfa3/fJ6xZs0Zbt2619HamCDGvoYYPH+7Nzc31vW5qavK6XC5vYWFhCLsKXG1trVeSd9OmTaFupU0OHTrkvfjii70lJSXeH//4x9477rgj1C2d1pw5c7wjR44MdRsBGz9+vPfmm2/223f99dd7s7OzQ9RR20jyrlmzxve6ubnZm5iY6P3tb3/r23fw4EGv0+n0PvvssyHosGXf77sl27dv90ry7tu3r2OaaoNT9f355597f/CDH3h37drl7dWrl/fRRx/t8N5gPSMn8BOPc8vIyPDtC9Xj3Nqrrq5OkhQXFxfiTtomNzdX48eP9/u778xeffVVDR06VD/72c8UHx+vIUOG6Mknnwx1W6268sorVVpaqk8//VSS9P777+udd95RVlZWiDsLTFVVldxut9+/L7GxsUpLSzPyd9XhcKhHjx6hbuW0mpubNWXKFM2ePVv9+/cPdTuwkJF3YutMj3Nrj+bmZs2cOVMjRozQgAEDQt1Oq5577jmVl5drx44doW6lzf76179q2bJlys/P1z333KMdO3bo9ttvV0REhHJyckLd3indfffd8ng86tOnj8LCwtTU1KSHHnpI2dnZoW4tICce9djS72owHgPZUY4ePao5c+boxhtv7BQPCjmdRYsWKTw8XLfffnuoW4HFjAzws0Vubq527dqld955J9SttKq6ulp33HGHSkpKOvzpP+3R3NysoUOHauHChZKkIUOGaNeuXVq+fHmnDvAXXnhBq1evVnFxsfr376+KigrNnDlTLperU/d9NmpsbNQNN9wgr9erZcuWhbqd0yorK9Njjz2m8vLyNj2OGWYzcgm9Mz3O7Uzl5eVp3bp12rhx4xk9PrWjlZWVqba2VpdddpnCw8MVHh6uTZs2aenSpQoPD1dTU1OoW2xRUlKS+vXr57evb9++2r9/f4g6apvZs2fr7rvv1uTJkzVw4EBNmTJFs2bNUmFhYahbC8iJ30dTf1dPhPe+fftUUlLS6afvt99+W7W1tUpJSfH9nu7bt0933nmnevfuHer2EGRGBnhnepxboLxer/Ly8rRmzRpt2LBBqampoW6pTcaMGaMPP/xQFRUVvm3o0KHKzs5WRUWFwsLCQt1ii0aMGHHS1/Q+/fRT9erVK0Qdtc2RI0fUpYv/r2dYWJiam5tD1NGZSU1NVWJiot/vqsfj0bZt2zr97+qJ8N6zZ4/efPNN9ezZM9QttWrKlCn64IMP/H5PXS6XZs+erddffz3U7SHIjF1C7yyPcwtUbm6uiouL9corryg6Otp3HTA2NlZRUVEh7u7UoqOjT7pO3717d/Xs2bNTX7+fNWuWrrzySi1cuFA33HCDtm/frhUrVmjFihWhbu20JkyYoIceekgpKSnq37+/3nvvPT3yyCO6+eabQ93aSQ4fPqy9e/f6XldVVamiokJxcXFKSUnRzJkz9eCDD+riiy9Wamqq5s6dK5fLpYkTJ4auaZ2+76SkJP30pz9VeXm51q1bp6amJt/valxcnCIiIkLVdqt/39//D42uXbsqMTFRl1xySUe3CquF+mPw7fH44497U1JSvBEREd7hw4d7t27dGuqWWiWpxW3lypWhbi1gJnyNzOv1el977TXvgAEDvE6n09unTx/vihUrQt1Sqzwej/eOO+7wpqSkeCMjI70XXnih9z//8z+9DQ0NoW7tJBs3bmzx3+mcnByv1/vtV8nmzp3rTUhI8DqdTu+YMWO8lZWVoW3ae/q+q6qqTvm7unHjxk7bd0v4GtnZi8eJAgBgICOvgQMAYHcEOAAABiLAAQAwEAEOAICBCHAAAAxEgAMAYCACHAAAAxHgAAAYiAAHAMBABDgAAAYiwAEAMBABDgCAgf4fJGgcWdCh1/sAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of the image:[3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建一个二维数据（假设是灰度值）\n",
    "data = loadmat('/Users/lvangge/Desktop/Archive/project1_release/codes/digits.mat')\n",
    "data_plot = data['X'][666].reshape(16,16)\n",
    "data_plot_index = data['y'][0]\n",
    "\n",
    "print(data_plot)\n",
    "plt.imshow(data_plot, cmap='gray', vmin=0, vmax=255)  # 设置颜色映射的范围\n",
    "plt.colorbar()  # 添加颜色条\n",
    "plt.show()\n",
    "print(f\"The index of the image:{data_plot_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533efff4-0249-4ace-bc56-62a701d0f2e6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**基于给定的初始代码，运行得到错误率**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db8718d-9d00-4d5f-98fc-b456c66663a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration = 0, validation error = 85.24%\n",
      "Training iteration = 500, validation error = 81.06%\n",
      "Training iteration = 1000, validation error = 77.94%\n",
      "Training iteration = 1500, validation error = 74.82%\n",
      "Training iteration = 2000, validation error = 67.78%\n",
      "Training iteration = 2500, validation error = 64.46%\n",
      "Training iteration = 3000, validation error = 63.16%\n",
      "Training iteration = 3500, validation error = 62.92%\n",
      "Training iteration = 4000, validation error = 59.22%\n",
      "Training iteration = 4500, validation error = 57.28%\n",
      "Training iteration = 5000, validation error = 59.18%\n",
      "Training iteration = 5500, validation error = 59.50%\n",
      "Training iteration = 6000, validation error = 60.18%\n",
      "Training iteration = 6500, validation error = 58.02%\n",
      "Training iteration = 7000, validation error = 58.52%\n",
      "Training iteration = 7500, validation error = 58.48%\n",
      "Training iteration = 8000, validation error = 57.82%\n",
      "Training iteration = 8500, validation error = 58.38%\n",
      "Training iteration = 9000, validation error = 56.68%\n",
      "Training iteration = 9500, validation error = 58.56%\n",
      "Test error with final model = 55.40%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load data\n",
    "data = loadmat('/Users/lvangge/Desktop/Archive/project1_release/codes/digits.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "nLabels = max(y)[0]\n",
    "Xvalid = data['Xvalid']\n",
    "Xtest = data['Xtest']\n",
    "yvalid = data['yvalid']\n",
    "ytest = data['ytest']\n",
    "\n",
    "# Function to expand y to binary matrix\n",
    "def linearInd2Binary(ind, nLabels):\n",
    "    n = len(ind)\n",
    "    y = -np.ones((n, nLabels))\n",
    "    for i in range(n):\n",
    "        y[i, int(ind[i])-1] = 1\n",
    "    return y\n",
    "\n",
    "yExpanded = linearInd2Binary(y,nLabels)\n",
    "\n",
    "def sech(x):\n",
    "    return 2 / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "# Standardize columns and add bias\n",
    "def standardize_cols(M, mu=None, sigma2=None):\n",
    "    M = M.astype(float)  # transform the matrix to float type\n",
    "    nrows, ncols = M.shape\n",
    "\n",
    "    if mu is None or sigma2 is None:\n",
    "        mu = np.mean(M, axis=0)\n",
    "        sigma2 = np.std(M, axis=0)\n",
    "        # handle the situation that sigma == 0\n",
    "        sigma2[sigma2 < np.finfo(float).eps] = 1\n",
    "\n",
    "    S = M - mu\n",
    "    if ncols > 0:\n",
    "        S = S / sigma2\n",
    "\n",
    "    return S, mu, sigma2\n",
    "\n",
    "def MLP_classification_loss(w, X, y, nHidden, nLabels):\n",
    "    nInstances, nVars = X.shape # the number of cases and character\n",
    "\n",
    "    # Form Weights\n",
    "    inputWeights = np.reshape(w[:nVars * nHidden[0]], (nVars, nHidden[0]))\n",
    "    offset = nVars * nHidden[0]\n",
    "    hiddenWeights = []\n",
    "    for h in range(2, len(nHidden) + 1):\n",
    "        hiddenWeights.append(np.reshape(w[offset:offset + nHidden[h-2] * nHidden[h-1]], (nHidden[h-2], nHidden[h-1])))\n",
    "        offset += nHidden[h-2] * nHidden[h-1]\n",
    "    outputWeights = np.reshape(w[offset:offset + nHidden[-1] * nLabels], (nHidden[-1], nLabels))\n",
    "\n",
    "    #Loss function and gradient\n",
    "    f = 0\n",
    "    gInput = np.zeros_like(inputWeights)\n",
    "    gHidden = [np.zeros_like(hidden) for hidden in hiddenWeights]\n",
    "    gOutput = np.zeros_like(outputWeights)\n",
    "\n",
    "    # Compute Output\n",
    "    for i in range(nInstances):\n",
    "        ip = [np.dot(X[i], inputWeights)]\n",
    "        fp = [np.tanh(ip[0])] # use tanh as activation function\n",
    "        for h in range(1, len(nHidden)):\n",
    "            ip.append(np.dot(fp[h-1], hiddenWeights[h-1]))\n",
    "            fp.append(np.tanh(ip[h]))\n",
    "        yhat = np.dot(fp[-1], outputWeights)\n",
    "\n",
    "        relativeErr = yhat - y[i]\n",
    "        f += np.sum(relativeErr ** 2) # use squared error\n",
    "\n",
    "        if gInput is not None:\n",
    "            err = 2 * relativeErr\n",
    "\n",
    "            # Output Weights\n",
    "            for c in range(nLabels):\n",
    "                gOutput[:, c] += err[c] * fp[-1]\n",
    "\n",
    "            if len(nHidden) > 1:\n",
    "                # Last Layer of Hidden Weights\n",
    "                backprop = np.zeros_like(hiddenWeights[-1])\n",
    "                for c in range(nLabels):\n",
    "                    backprop[c, :] = err[c] * (np.sech(ip[-1]) ** 2) * outputWeights[:, c]\n",
    "                    gHidden[-1] += np.outer(fp[-2], backprop[c, :])\n",
    "                backprop = np.sum(backprop, axis=0)\n",
    "\n",
    "                # Other Hidden Layers\n",
    "                for h in range(len(nHidden) - 2, 0, -1):\n",
    "                    backprop = np.dot(backprop, hiddenWeights[h].T) * (sech(ip[h]) ** 2)\n",
    "                    gHidden[h-1] += np.outer(fp[h-1], backprop)\n",
    "\n",
    "                # Input Weights\n",
    "                backprop = np.dot(backprop, hiddenWeights[0].T) * (sech(ip[0]) ** 2)\n",
    "                gInput += np.outer(X[i], backprop)\n",
    "            else:\n",
    "                # Input Weights\n",
    "                for c in range(nLabels):\n",
    "                    gInput += err[c] * np.outer(X[i], (sech(ip[-1]) ** 2) * outputWeights[:, c])\n",
    "\n",
    "    # Put Gradient into vector\n",
    "    g = np.concatenate([gInput.flatten(), *[grad.flatten() for grad in gHidden], gOutput.flatten()])\n",
    "\n",
    "    return f, g\n",
    "\n",
    "def MLP_classification_predict(w, X, nHidden, nLabels):\n",
    "    nInstances, nVars = X.shape\n",
    "\n",
    "    # Form Weights\n",
    "    inputWeights = np.reshape(w[:nVars * nHidden[0]], (nVars, nHidden[0]))\n",
    "    offset = nVars * nHidden[0]\n",
    "    hiddenWeights = []\n",
    "    for h in range(2, len(nHidden) + 1):\n",
    "        hiddenWeights.append(np.reshape(w[offset:offset + nHidden[h-2] * nHidden[h-1]], (nHidden[h-2], nHidden[h-1])))\n",
    "        offset += nHidden[h-2] * nHidden[h-1]\n",
    "    outputWeights = np.reshape(w[offset:offset + nHidden[-1] * nLabels], (nHidden[-1], nLabels))\n",
    "\n",
    "    # Compute Output\n",
    "    y = np.zeros((nInstances, nLabels))\n",
    "    for i in range(nInstances):\n",
    "        ip = [np.dot(X[i], inputWeights)]\n",
    "        fp = [np.tanh(ip[0])]\n",
    "        for h in range(1, len(nHidden)):\n",
    "            ip.append(np.dot(fp[h-1], hiddenWeights[h-1]))\n",
    "            fp.append(np.tanh(ip[h]))\n",
    "        y[i] = np.dot(fp[-1], outputWeights)\n",
    "\n",
    "    y = np.argmax(y, axis=1) + 1\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "X, mu, sigma = standardize_cols(X)\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X)) # add bias column\n",
    "\n",
    "Xvalid = standardize_cols(Xvalid, mu, sigma)[0]\n",
    "Xvalid = np.hstack((np.ones((Xvalid.shape[0], 1)), Xvalid))\n",
    "\n",
    "Xtest = standardize_cols(Xtest, mu, sigma)[0]\n",
    "Xtest = np.hstack((np.ones((Xtest.shape[0], 1)), Xtest))\n",
    "\n",
    "# Choose network structure\n",
    "nHidden = [10]\n",
    "\n",
    "# Initialize weights 'w'\n",
    "nParams = X.shape[1] * nHidden[0]\n",
    "for h in range(1, len(nHidden)):\n",
    "    nParams += nHidden[h-1] * nHidden[h]\n",
    "nParams += nHidden[-1] * np.max(y)\n",
    "w = np.random.randn(nParams)\n",
    "\n",
    "# Train with stochastic gradient descent\n",
    "maxIter = 10000\n",
    "stepSize = 1e-3\n",
    "for iter in range(1, maxIter+1):\n",
    "    if (iter-1) % round(maxIter/20) == 0:\n",
    "        yhat = MLP_classification_predict(w, Xvalid, nHidden, np.max(y))\n",
    "        print(f'Training iteration = {iter-1}, validation error = {np.sum(yhat != yvalid.reshape(Xvalid.shape[0]))/Xvalid.shape[0]:.2%}')\n",
    "    \n",
    "    i = np.random.randint(0, len(X))\n",
    "    X_i = X[i].reshape(1, -1)\n",
    "    yExpanded_i = yExpanded[i].reshape(1, -1)\n",
    "    f, g = MLP_classification_loss(w, X_i, yExpanded_i, nHidden, np.max(y))\n",
    "    w = w - stepSize * g\n",
    "\n",
    "# Evaluate test error\n",
    "yhat = MLP_classification_predict(w, Xtest, nHidden, np.max(y))\n",
    "print(f'Test error with final model = {np.sum([yhat[i]!=ytest[i] for i in range(len(ytest))])/len(ytest):.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52f35b-7474-452b-b62f-14be1b8b124a",
   "metadata": {},
   "source": [
    "**<span style=\"font-size:18pt\">尝试修改神经网络层结构</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a2ba475-1b27-4533-a3a5-d57f7295d202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration = 0, validation error = 90.56%\n",
      "Training iteration = 500, validation error = 42.42%\n",
      "Training iteration = 1000, validation error = 42.12%\n",
      "Training iteration = 1500, validation error = 43.10%\n",
      "Training iteration = 2000, validation error = 45.92%\n",
      "Training iteration = 2500, validation error = 42.68%\n",
      "Training iteration = 3000, validation error = 53.02%\n",
      "Training iteration = 3500, validation error = 45.82%\n",
      "Training iteration = 4000, validation error = 51.14%\n",
      "Training iteration = 4500, validation error = 40.16%\n",
      "Training iteration = 5000, validation error = 38.88%\n",
      "Training iteration = 5500, validation error = 41.96%\n",
      "Training iteration = 6000, validation error = 37.50%\n",
      "Training iteration = 6500, validation error = 41.48%\n",
      "Training iteration = 7000, validation error = 42.32%\n",
      "Training iteration = 7500, validation error = 43.06%\n",
      "Training iteration = 8000, validation error = 47.36%\n",
      "Training iteration = 8500, validation error = 52.52%\n",
      "Training iteration = 9000, validation error = 42.06%\n",
      "Training iteration = 9500, validation error = 41.76%\n",
      "Test error with final model = 41.10%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import copy\n",
    "\n",
    "# Load data\n",
    "data = loadmat('/Users/lvangge/Desktop/Archive/project1_release/codes/digits.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "nLabels = max(y)[0]\n",
    "Xvalid = data['Xvalid']\n",
    "Xtest = data['Xtest']\n",
    "yvalid = data['yvalid']\n",
    "ytest = data['ytest']\n",
    "\n",
    "# Function to expand y to binary matrix\n",
    "def linearInd2Binary(ind, nLabels):\n",
    "    n = len(ind)\n",
    "    y = -np.ones((n, nLabels))\n",
    "    for i in range(n):\n",
    "        y[i, int(ind[i])-1] = 1\n",
    "    return y\n",
    "\n",
    "yExpanded = linearInd2Binary(y,nLabels)\n",
    "\n",
    "def sech(x):\n",
    "    return 2 / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "# Standardize columns and add bias\n",
    "def standardize_cols(M, mu=None, sigma2=None):\n",
    "    M = M.astype(float)  # transform the matrix to float type\n",
    "    nrows, ncols = M.shape\n",
    "\n",
    "    if mu is None or sigma2 is None:\n",
    "        mu = np.mean(M, axis=0)\n",
    "        sigma2 = np.std(M, axis=0)\n",
    "        # handle the situation that sigma == 0\n",
    "        sigma2[sigma2 < np.finfo(float).eps] = 1\n",
    "\n",
    "    S = M - mu\n",
    "    if ncols > 0:\n",
    "        S = S / sigma2\n",
    "\n",
    "    return S, mu, sigma2\n",
    "\n",
    "def MLP_classification_loss(w, X, y, nHidden, nLabels, lam=0.5):\n",
    "    nInstances, nVars = X.shape # the number of cases and character\n",
    "\n",
    "    # Form Weights\n",
    "    inputWeights = np.reshape(w[:nVars * nHidden[0]], (nVars, nHidden[0]))\n",
    "    offset = nVars * nHidden[0]\n",
    "    hiddenWeights = []\n",
    "    for h in range(2, len(nHidden) + 1):\n",
    "        hiddenWeights.append(np.reshape(w[offset:offset + nHidden[h-2] * nHidden[h-1]], (nHidden[h-2], nHidden[h-1])))\n",
    "        offset += nHidden[h-2] * nHidden[h-1]\n",
    "    outputWeights = np.reshape(w[offset:offset + nHidden[-1] * nLabels], (nHidden[-1], nLabels))\n",
    "\n",
    "    #Loss function and gradient\n",
    "    f = 0\n",
    "    gInput = np.zeros_like(inputWeights)\n",
    "    gHidden = [np.zeros_like(hidden) for hidden in hiddenWeights]\n",
    "    gOutput = np.zeros_like(outputWeights)\n",
    "\n",
    "    # Compute Output\n",
    "    for i in range(nInstances):\n",
    "        ip = [np.dot(X[i], inputWeights)]\n",
    "        fp = [np.tanh(ip[0])] # use tanh as activation function\n",
    "        for h in range(1, len(nHidden)):\n",
    "            ip.append(np.dot(fp[h-1], hiddenWeights[h-1]))\n",
    "            fp.append(np.tanh(ip[h]))\n",
    "        yhat = np.dot(fp[-1], outputWeights)\n",
    "\n",
    "        relativeErr = yhat - y[i]\n",
    "        f += np.sum(relativeErr ** 2) / (nInstances * nLabels)  # use squared error\n",
    "\n",
    "        if gInput is not None:\n",
    "            err = 2 * relativeErr\n",
    "\n",
    "            # Output Weights\n",
    "            for c in range(nLabels):\n",
    "                gOutput[:, c] += err[c] * fp[-1]\n",
    "\n",
    "            if len(nHidden) > 1:\n",
    "                # Last Layer of Hidden Weights\n",
    "                backprop = np.zeros_like(hiddenWeights[-1])\n",
    "                for c in range(nLabels):\n",
    "                    backprop[c, :] = err[c] * (sech(ip[-1]) ** 2) * outputWeights[:, c]\n",
    "                    gHidden[-1] += np.outer(fp[-2], backprop[c, :])\n",
    "                backprop = np.sum(backprop, axis=0)\n",
    "\n",
    "                # Other Hidden Layers\n",
    "                for h in range(len(nHidden) - 2, 0, -1):\n",
    "                    backprop = np.dot(backprop, hiddenWeights[h].T) * (sech(ip[h]) ** 2)\n",
    "                    gHidden[h-1] += np.outer(fp[h-1], backprop)\n",
    "\n",
    "                # Input Weights\n",
    "                backprop = np.dot(backprop, hiddenWeights[0].T) * (sech(ip[0]) ** 2)\n",
    "                gInput += np.outer(X[i], backprop)\n",
    "            else:\n",
    "                # Input Weights\n",
    "                for c in range(nLabels):\n",
    "                    gInput += err[c] * np.outer(X[i], (sech(ip[-1]) ** 2) * outputWeights[:, c])\n",
    "    # add l2 regulation\n",
    "    f += 0.5 * lam * (np.sum(inputWeights ** 2) + np.sum(outputWeights ** 2))\n",
    "    for hidden in hiddenWeights:\n",
    "        f += 0.5 * lam * np.sum(hidden ** 2)\n",
    "    \n",
    "    #l2 term\n",
    "    gInput += lam * inputWeights\n",
    "    for h in range(len(nHidden)-1):\n",
    "        gHidden[h] += lam * hiddenWeights[h]\n",
    "    gOutput += lam * outputWeights\n",
    "\n",
    "    # Put Gradient into vector\n",
    "    g = np.concatenate([gInput.flatten(), *[grad.flatten() for grad in gHidden], gOutput.flatten()])\n",
    "\n",
    "    return f, g\n",
    "\n",
    "def MLP_classification_predict(w, X, nHidden, nLabels):\n",
    "    nInstances, nVars = X.shape\n",
    "\n",
    "    # Form Weights\n",
    "    inputWeights = np.reshape(w[:nVars * nHidden[0]], (nVars, nHidden[0]))\n",
    "    offset = nVars * nHidden[0]\n",
    "    hiddenWeights = []\n",
    "    for h in range(2, len(nHidden) + 1):\n",
    "        hiddenWeights.append(np.reshape(w[offset:offset + nHidden[h-2] * nHidden[h-1]], (nHidden[h-2], nHidden[h-1])))\n",
    "        offset += nHidden[h-2] * nHidden[h-1]\n",
    "    outputWeights = np.reshape(w[offset:offset + nHidden[-1] * nLabels], (nHidden[-1], nLabels))\n",
    "\n",
    "    # Compute Output\n",
    "    y = np.zeros((nInstances, nLabels))\n",
    "    for i in range(nInstances):\n",
    "        ip = [np.dot(X[i], inputWeights)]\n",
    "        fp = [np.tanh(ip[0])]\n",
    "        for h in range(1, len(nHidden)):\n",
    "            ip.append(np.dot(fp[h-1], hiddenWeights[h-1]))\n",
    "            fp.append(np.tanh(ip[h]))\n",
    "        y[i] = np.dot(fp[-1], outputWeights)\n",
    "\n",
    "    y = np.argmax(y, axis=1) + 1\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "X, mu, sigma = standardize_cols(X)\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X)) # add bias column\n",
    "\n",
    "Xvalid = standardize_cols(Xvalid, mu, sigma)[0]\n",
    "Xvalid = np.hstack((np.ones((Xvalid.shape[0], 1)), Xvalid))\n",
    "\n",
    "Xtest = standardize_cols(Xtest, mu, sigma)[0]\n",
    "Xtest = np.hstack((np.ones((Xtest.shape[0], 1)), Xtest))\n",
    "\n",
    "# Choose network structure\n",
    "nHidden = [50]\n",
    "\n",
    "# Initialize weights 'w'\n",
    "nParams = X.shape[1] * nHidden[0]\n",
    "for h in range(1, len(nHidden)):\n",
    "    nParams += nHidden[h-1] * nHidden[h]\n",
    "nParams += nHidden[-1] * np.max(y)\n",
    "w = np.random.randn(nParams)\n",
    "\n",
    "# Train with stochastic gradient descent\n",
    "maxIter = 10000\n",
    "stepSize = 1e-3\n",
    "momentum = 0.9\n",
    "w_history = [w]\n",
    "for iter in range(1, maxIter+1):\n",
    "    if (iter-1) % round(maxIter/20) == 0:\n",
    "        yhat = MLP_classification_predict(w, Xvalid, nHidden, np.max(y))\n",
    "        print(f'Training iteration = {iter-1}, validation error = {np.sum(yhat != yvalid.reshape(Xvalid.shape[0]))/Xvalid.shape[0]:.2%}')\n",
    "    \n",
    "    i = np.random.randint(0, len(X))\n",
    "    X_i = X[i].reshape(1, -1)\n",
    "    yExpanded_i = yExpanded[i].reshape(1, -1)\n",
    "    f, g = MLP_classification_loss(w, X_i, yExpanded_i, nHidden, np.max(y))\n",
    "    w_history.append(w)\n",
    "    w = w - stepSize * g + momentum * (w - w_history[0])\n",
    "    w_history.pop(0)\n",
    "# Evaluate test error\n",
    "yhat = MLP_classification_predict(w, Xtest, nHidden, np.max(y))\n",
    "print(f'Test error with final model = {np.sum([yhat[i]!=ytest[i] for i in range(len(ytest))])/len(ytest):.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83620b-8bd8-4f7f-bf95-42c2201e5b7d",
   "metadata": {},
   "source": [
    "**<span style=\"font-size:18pt\">修改激活函数为softmax函数,使用交叉熵函数作为损失函数,y的编码为{0,1}的one-hot编码</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbeff87d-cc72-497f-8394-907a1041767a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration = 0,Loss=57018.86,validation error = 92.24%\n",
      "Training iteration = 500,Loss=27783.98,validation error = 71.28%\n",
      "Training iteration = 1000,Loss=18285.36,validation error = 58.10%\n",
      "Training iteration = 1500,Loss=13838.29,validation error = 48.78%\n",
      "Training iteration = 2000,Loss=11254.02,validation error = 43.20%\n",
      "Training iteration = 2500,Loss=9819.82,validation error = 40.26%\n",
      "Training iteration = 3000,Loss=8740.41,validation error = 36.66%\n",
      "Training iteration = 3500,Loss=8015.45,validation error = 33.86%\n",
      "Training iteration = 4000,Loss=7507.07,validation error = 31.66%\n",
      "Training iteration = 4500,Loss=7114.07,validation error = 30.44%\n",
      "Training iteration = 5000,Loss=6539.74,validation error = 29.40%\n",
      "Training iteration = 5500,Loss=6218.05,validation error = 28.40%\n",
      "Training iteration = 6000,Loss=5948.28,validation error = 27.56%\n",
      "Training iteration = 6500,Loss=5736.81,validation error = 26.94%\n",
      "Training iteration = 7000,Loss=5430.60,validation error = 26.08%\n",
      "Training iteration = 7500,Loss=5259.57,validation error = 25.72%\n",
      "Training iteration = 8000,Loss=5097.52,validation error = 24.52%\n",
      "Training iteration = 8500,Loss=4967.02,validation error = 24.04%\n",
      "Training iteration = 9000,Loss=4864.97,validation error = 23.84%\n",
      "Training iteration = 9500,Loss=4787.74,validation error = 23.18%\n",
      "Test error with final model = 24.40%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import copy\n",
    "\n",
    "# Load data\n",
    "data = loadmat('/Users/lvangge/Desktop/Archive/project1_release/codes/digits.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "nLabels = max(y)[0]\n",
    "Xvalid = data['Xvalid']\n",
    "Xtest = data['Xtest']\n",
    "yvalid = data['yvalid']\n",
    "ytest = data['ytest']\n",
    "\n",
    "# Function to expand y to binary matrix\n",
    "def linearInd2Binary(ind, nLabels):\n",
    "    n = len(ind)\n",
    "    y = np.zeros((n, nLabels))\n",
    "    for i in range(n):\n",
    "        y[i, int(ind[i])-1] = 1\n",
    "    return y\n",
    "\n",
    "yExpanded = linearInd2Binary(y,nLabels)\n",
    "\n",
    "def sech(x):\n",
    "    return 2 / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, keepdims=True)\n",
    "\n",
    "# Standardize columns and add bias\n",
    "def standardize_cols(M, mu=None, sigma2=None):\n",
    "    M = M.astype(float)  # transform the matrix to float type\n",
    "    nrows, ncols = M.shape\n",
    "\n",
    "    if mu is None or sigma2 is None:\n",
    "        mu = np.mean(M, axis=0)\n",
    "        sigma2 = np.std(M, axis=0)\n",
    "        # handle the situation that sigma == 0\n",
    "        sigma2[sigma2 < np.finfo(float).eps] = 1\n",
    "\n",
    "    S = M - mu\n",
    "    if ncols > 0:\n",
    "        S = S / sigma2\n",
    "\n",
    "    return S, mu, sigma2\n",
    "\n",
    "def MLP_classification_loss(w, X, y, nHidden, nLabels):\n",
    "    nInstances, nVars = X.shape # the number of cases and character\n",
    "\n",
    "    # Form Weights\n",
    "    inputWeights = np.reshape(w[:nVars * nHidden[0]], (nVars, nHidden[0]))\n",
    "    offset = nVars * nHidden[0]\n",
    "    hiddenWeights = []\n",
    "    for h in range(2, len(nHidden) + 1):\n",
    "        hiddenWeights.append(np.reshape(w[offset:offset + nHidden[h-2] * nHidden[h-1]], (nHidden[h-2], nHidden[h-1])))\n",
    "        offset += nHidden[h-2] * nHidden[h-1]\n",
    "    outputWeights = np.reshape(w[offset:offset + nHidden[-1] * nLabels], (nHidden[-1], nLabels))\n",
    "\n",
    "    #Loss function and gradient\n",
    "    f = 0\n",
    "    gInput = np.zeros_like(inputWeights)\n",
    "    gHidden = [np.zeros_like(hidden) for hidden in hiddenWeights]\n",
    "    gOutput = np.zeros_like(outputWeights)\n",
    "\n",
    "    # Compute Output\n",
    "    for i in range(nInstances):\n",
    "        ip = [np.dot(X[i], inputWeights)]\n",
    "        fp = [np.tanh(ip[0])] # use tanh as activation function\n",
    "        for h in range(1, len(nHidden)):\n",
    "            ip.append(np.dot(fp[h-1], hiddenWeights[h-1]))\n",
    "            fp.append(np.tanh(ip[h]))\n",
    "        logits = np.dot(fp[-1], outputWeights)\n",
    "        probs = softmax(logits)\n",
    "\n",
    "        f += -np.dot(np.log(probs + 1e-10), y[i])\n",
    "\n",
    "        if gInput is not None:\n",
    "            err = probs - y[i]  # Gradient of the softmax output\n",
    "\n",
    "            # Output Weights\n",
    "            gOutput += np.outer(fp[-1], err)\n",
    "\n",
    "            if len(nHidden) > 1:\n",
    "                # Last Layer of Hidden Weights\n",
    "                backprop = np.dot(err, outputWeights.T) * (sech(ip[-1]) ** 2)\n",
    "                gHidden[-1] += np.outer(fp[-2], backprop)\n",
    "\n",
    "                # Other Hidden Layers\n",
    "                for h in range(len(nHidden) - 2, 0, -1):\n",
    "                    backprop = np.dot(backprop, hiddenWeights[h].T) * (sech(ip[h]) ** 2)\n",
    "                    gHidden[h-1] += np.outer(fp[h-1], backprop)\n",
    "\n",
    "                # Input Weights\n",
    "                backprop = np.dot(backprop, hiddenWeights[0].T) * (sech(ip[0]) ** 2)\n",
    "                gInput += np.outer(X[i], backprop)\n",
    "            else:\n",
    "                # Input Weights\n",
    "                gInput += np.outer(X[i], (sech(ip[-1]) ** 2) * np.dot(err, outputWeights.T))\n",
    "\n",
    "    # Put Gradient into vector\n",
    "    g = np.concatenate([gInput.flatten(), *[grad.flatten() for grad in gHidden], gOutput.flatten()])\n",
    "\n",
    "    return f, g\n",
    "\n",
    "def MLP_classification_predict(w, X, nHidden, nLabels):\n",
    "    nInstances, nVars = X.shape\n",
    "\n",
    "    # Form Weights\n",
    "    inputWeights = np.reshape(w[:nVars * nHidden[0]], (nVars, nHidden[0]))\n",
    "    offset = nVars * nHidden[0]\n",
    "    hiddenWeights = []\n",
    "    for h in range(2, len(nHidden) + 1):\n",
    "        hiddenWeights.append(np.reshape(w[offset:offset + nHidden[h-2] * nHidden[h-1]], (nHidden[h-2], nHidden[h-1])))\n",
    "        offset += nHidden[h-2] * nHidden[h-1]\n",
    "    outputWeights = np.reshape(w[offset:offset + nHidden[-1] * nLabels], (nHidden[-1], nLabels))\n",
    "\n",
    "    # Compute Output\n",
    "    y = np.zeros((nInstances, nLabels))\n",
    "    for i in range(nInstances):\n",
    "        ip = [np.dot(X[i], inputWeights)]\n",
    "        fp = [np.tanh(ip[0])]\n",
    "        for h in range(1, len(nHidden)):\n",
    "            ip.append(np.dot(fp[h-1], hiddenWeights[h-1]))\n",
    "            fp.append(np.tanh(ip[h]))\n",
    "        y[i] = np.dot(fp[-1], outputWeights)\n",
    "\n",
    "    y = np.argmax(y, axis=1) + 1\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "X, mu, sigma = standardize_cols(X)\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X)) # add bias column\n",
    "\n",
    "Xvalid = standardize_cols(Xvalid, mu, sigma)[0]\n",
    "Xvalid = np.hstack((np.ones((Xvalid.shape[0], 1)), Xvalid))\n",
    "\n",
    "Xtest = standardize_cols(Xtest, mu, sigma)[0]\n",
    "Xtest = np.hstack((np.ones((Xtest.shape[0], 1)), Xtest))\n",
    "\n",
    "# Choose network structure\n",
    "nHidden = [50]\n",
    "\n",
    "# Initialize weights 'w'\n",
    "nParams = X.shape[1] * nHidden[0]\n",
    "for h in range(1, len(nHidden)):\n",
    "    nParams += nHidden[h-1] * nHidden[h]\n",
    "nParams += nHidden[-1] * np.max(y)\n",
    "w = np.random.randn(nParams)\n",
    "\n",
    "# Train with stochastic gradient descent\n",
    "maxIter = 10000\n",
    "stepSize = 1e-3\n",
    "momentum = 0.9\n",
    "w_history = [w]\n",
    "for iter in range(1, maxIter+1):\n",
    "    if (iter-1) % round(maxIter/20) == 0:\n",
    "        yhat = MLP_classification_predict(w, Xvalid, nHidden, np.max(y))\n",
    "        f = MLP_classification_loss(w, Xvalid, linearInd2Binary(yvalid,nLabels), nHidden, np.max(y))[0]\n",
    "        print(f'Training iteration = {iter-1},Loss={f:.2f},validation error = {np.sum(yhat != yvalid.reshape(Xvalid.shape[0]))/Xvalid.shape[0]:.2%}')\n",
    "    \n",
    "    i = np.random.randint(0, len(X))\n",
    "    X_i = X[i].reshape(1, -1)\n",
    "    yExpanded_i = yExpanded[i].reshape(1, -1)\n",
    "    f, g = MLP_classification_loss(w, X_i, yExpanded_i, nHidden, np.max(y))\n",
    "    w_history.append(w)\n",
    "    w = w - stepSize * g + momentum * (w - w_history[0])\n",
    "    w_history.pop(0)\n",
    "# Evaluate test error\n",
    "yhat = MLP_classification_predict(w, Xtest, nHidden, np.max(y))\n",
    "print(f'Test error with final model = {np.sum([yhat[i]!=ytest[i] for i in range(len(ytest))])/len(ytest):.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf5bb7-61e5-4105-914c-93e8f37fe233",
   "metadata": {},
   "source": [
    "\n",
    "**<span style=\"font-size:18pt\">加上l2正则化项</span>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d02afba3-2374-4e3c-9fec-73ef3ca62046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration = 0,f=58161.51,validation error = 91.42%\n",
      "Training iteration = 500,f=7433.41,validation error = 35.46%\n",
      "Training iteration = 1000,f=8388.55,validation error = 38.02%\n",
      "Training iteration = 1500,f=8332.58,validation error = 45.62%\n",
      "Training iteration = 2000,f=8445.34,validation error = 50.04%\n",
      "Training iteration = 2500,f=8538.77,validation error = 47.64%\n",
      "Training iteration = 3000,f=8430.35,validation error = 44.56%\n",
      "Training iteration = 3500,f=8370.47,validation error = 51.24%\n",
      "Training iteration = 4000,f=8464.29,validation error = 37.98%\n",
      "Training iteration = 4500,f=8324.32,validation error = 46.00%\n",
      "Training iteration = 5000,f=8661.54,validation error = 44.18%\n",
      "Training iteration = 5500,f=8513.72,validation error = 39.44%\n",
      "Training iteration = 6000,f=8572.65,validation error = 40.56%\n",
      "Training iteration = 6500,f=8467.18,validation error = 44.82%\n",
      "Training iteration = 7000,f=8380.76,validation error = 50.88%\n",
      "Training iteration = 7500,f=8390.46,validation error = 49.64%\n",
      "Training iteration = 8000,f=8393.68,validation error = 44.50%\n",
      "Training iteration = 8500,f=8316.20,validation error = 45.70%\n",
      "Training iteration = 9000,f=8488.10,validation error = 37.78%\n",
      "Training iteration = 9500,f=8509.46,validation error = 47.52%\n",
      "Test error with final model = 47.30%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import copy\n",
    "\n",
    "# Load data\n",
    "data = loadmat('/Users/lvangge/Desktop/Archive/project1_release/codes/digits.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "nLabels = max(y)[0]\n",
    "Xvalid = data['Xvalid']\n",
    "Xtest = data['Xtest']\n",
    "yvalid = data['yvalid']\n",
    "ytest = data['ytest']\n",
    "\n",
    "# Function to expand y to binary matrix\n",
    "def linearInd2Binary(ind, nLabels):\n",
    "    n = len(ind)\n",
    "    y = np.zeros((n, nLabels))\n",
    "    for i in range(n):\n",
    "        y[i, int(ind[i])-1] = 1\n",
    "    return y\n",
    "\n",
    "yExpanded = linearInd2Binary(y,nLabels)\n",
    "\n",
    "def sech(x):\n",
    "    return 2 / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, keepdims=True)\n",
    "\n",
    "# Standardize columns and add bias\n",
    "def standardize_cols(M, mu=None, sigma2=None):\n",
    "    M = M.astype(float)  # transform the matrix to float type\n",
    "    nrows, ncols = M.shape\n",
    "\n",
    "    if mu is None or sigma2 is None:\n",
    "        mu = np.mean(M, axis=0)\n",
    "        sigma2 = np.std(M, axis=0)\n",
    "        # handle the situation that sigma == 0\n",
    "        sigma2[sigma2 < np.finfo(float).eps] = 1\n",
    "\n",
    "    S = M - mu\n",
    "    if ncols > 0:\n",
    "        S = S / sigma2\n",
    "\n",
    "    return S, mu, sigma2\n",
    "\n",
    "def MLP_classification_loss(w, X, y, nHidden, nLabels, lam=0.5):\n",
    "    nInstances, nVars = X.shape # the number of cases and character\n",
    "\n",
    "    # Form Weights\n",
    "    inputWeights = np.reshape(w[:nVars * nHidden[0]], (nVars, nHidden[0]))\n",
    "    offset = nVars * nHidden[0]\n",
    "    hiddenWeights = []\n",
    "    for h in range(2, len(nHidden) + 1):\n",
    "        hiddenWeights.append(np.reshape(w[offset:offset + nHidden[h-2] * nHidden[h-1]], (nHidden[h-2], nHidden[h-1])))\n",
    "        offset += nHidden[h-2] * nHidden[h-1]\n",
    "    outputWeights = np.reshape(w[offset:offset + nHidden[-1] * nLabels], (nHidden[-1], nLabels))\n",
    "\n",
    "    #Loss function and gradient\n",
    "    f = 0\n",
    "    gInput = np.zeros_like(inputWeights)\n",
    "    gHidden = [np.zeros_like(hidden) for hidden in hiddenWeights]\n",
    "    gOutput = np.zeros_like(outputWeights)\n",
    "\n",
    "    # Compute Output\n",
    "    for i in range(nInstances):\n",
    "        ip = [np.dot(X[i], inputWeights)]\n",
    "        fp = [np.tanh(ip[0])] # use tanh as activation function\n",
    "        for h in range(1, len(nHidden)):\n",
    "            ip.append(np.dot(fp[h-1], hiddenWeights[h-1]))\n",
    "            fp.append(np.tanh(ip[h]))\n",
    "        logits = np.dot(fp[-1], outputWeights)\n",
    "        probs = softmax(logits)\n",
    "\n",
    "        f += -np.dot(np.log(probs + 1e-10), y[i])\n",
    "\n",
    "        if gInput is not None:\n",
    "            err = probs - y[i]  # Gradient of the softmax output\n",
    "\n",
    "            # Output Weights\n",
    "            gOutput += np.outer(fp[-1], err)\n",
    "\n",
    "            if len(nHidden) > 1:\n",
    "                # Last Layer of Hidden Weights\n",
    "                backprop = np.dot(err, outputWeights.T) * (sech(ip[-1]) ** 2)\n",
    "                gHidden[-1] += np.outer(fp[-2], backprop)\n",
    "\n",
    "                # Other Hidden Layers\n",
    "                for h in range(len(nHidden) - 2, 0, -1):\n",
    "                    backprop = np.dot(backprop, hiddenWeights[h].T) * (sech(ip[h]) ** 2)\n",
    "                    gHidden[h-1] += np.outer(fp[h-1], backprop)\n",
    "\n",
    "                # Input Weights\n",
    "                backprop = np.dot(backprop, hiddenWeights[0].T) * (sech(ip[0]) ** 2)\n",
    "                gInput += np.outer(X[i], backprop)\n",
    "            else:\n",
    "                # Input Weights\n",
    "                gInput += np.outer(X[i], (sech(ip[-1]) ** 2) * np.dot(err, outputWeights.T))\n",
    "\n",
    "    # Put Gradient into vector\n",
    "    g = np.concatenate([gInput.flatten(), *[grad.flatten() for grad in gHidden], gOutput.flatten()])\n",
    "\n",
    "    # Add the l2 regulation term for Loss\n",
    "    # f /= nInstances\n",
    "    f += 0.5 * lam * (np.sum(inputWeights ** 2) + np.sum(outputWeights ** 2))\n",
    "    for hidden in hiddenWeights:\n",
    "        f += 0.5 * lam * np.sum(hidden ** 2)\n",
    "\n",
    "    # Add the l2 regulatiuon term for gradient\n",
    "    gInput += lam * inputWeights\n",
    "    for h in range(len(nHidden)-1):\n",
    "        gHidden[h] += lam * hiddenWeights[h]\n",
    "    gOutput += lam * outputWeights\n",
    "\n",
    "    # Put Gradient into vector\n",
    "    g = np.concatenate([gInput.flatten(), *[grad.flatten() for grad in gHidden], gOutput.flatten()])\n",
    "    \n",
    "    return f, g\n",
    "\n",
    "def MLP_classification_predict(w, X, nHidden, nLabels):\n",
    "    nInstances, nVars = X.shape\n",
    "\n",
    "    # Form Weights\n",
    "    inputWeights = np.reshape(w[:nVars * nHidden[0]], (nVars, nHidden[0]))\n",
    "    offset = nVars * nHidden[0]\n",
    "    hiddenWeights = []\n",
    "    for h in range(2, len(nHidden) + 1):\n",
    "        hiddenWeights.append(np.reshape(w[offset:offset + nHidden[h-2] * nHidden[h-1]], (nHidden[h-2], nHidden[h-1])))\n",
    "        offset += nHidden[h-2] * nHidden[h-1]\n",
    "    outputWeights = np.reshape(w[offset:offset + nHidden[-1] * nLabels], (nHidden[-1], nLabels))\n",
    "\n",
    "    # Compute Output\n",
    "    y = np.zeros((nInstances, nLabels))\n",
    "    for i in range(nInstances):\n",
    "        ip = [np.dot(X[i], inputWeights)]\n",
    "        fp = [np.tanh(ip[0])]\n",
    "        for h in range(1, len(nHidden)):\n",
    "            ip.append(np.dot(fp[h-1], hiddenWeights[h-1]))\n",
    "            fp.append(np.tanh(ip[h]))\n",
    "        y[i] = np.dot(fp[-1], outputWeights)\n",
    "\n",
    "    y = np.argmax(y, axis=1) + 1\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "X, mu, sigma = standardize_cols(X)\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X)) # add bias column\n",
    "\n",
    "Xvalid = standardize_cols(Xvalid, mu, sigma)[0]\n",
    "Xvalid = np.hstack((np.ones((Xvalid.shape[0], 1)), Xvalid))\n",
    "\n",
    "Xtest = standardize_cols(Xtest, mu, sigma)[0]\n",
    "Xtest = np.hstack((np.ones((Xtest.shape[0], 1)), Xtest))\n",
    "\n",
    "# Choose network structure\n",
    "nHidden = [50]\n",
    "\n",
    "# Initialize weights 'w'\n",
    "nParams = X.shape[1] * nHidden[0]\n",
    "for h in range(1, len(nHidden)):\n",
    "    nParams += nHidden[h-1] * nHidden[h]\n",
    "nParams += nHidden[-1] * np.max(y)\n",
    "w = np.random.randn(nParams)\n",
    "\n",
    "# Train with stochastic gradient descent\n",
    "maxIter = 10000\n",
    "stepSize = 1e-3\n",
    "momentum = 0.9\n",
    "w_history = [w]\n",
    "for iter in range(1, maxIter+1):\n",
    "    if (iter-1) % round(maxIter/20) == 0:\n",
    "        yhat = MLP_classification_predict(w, Xvalid, nHidden, np.max(y))\n",
    "        f = MLP_classification_loss(w, Xvalid, linearInd2Binary(yvalid,nLabels), nHidden, np.max(y))[0]\n",
    "        print(f'Training iteration = {iter-1},f={f:.2f},validation error = {np.sum(yhat != yvalid.reshape(Xvalid.shape[0]))/Xvalid.shape[0]:.2%}')\n",
    "    \n",
    "    i = np.random.randint(0, len(X))\n",
    "    X_i = X[i].reshape(1, -1)\n",
    "    yExpanded_i = yExpanded[i].reshape(1, -1)\n",
    "    f, g = MLP_classification_loss(w, X_i, yExpanded_i, nHidden, np.max(y))\n",
    "    w_history.append(w)\n",
    "    w = w - stepSize * g + momentum * (w - w_history[0])\n",
    "    w_history.pop(0)\n",
    "# Evaluate test error\n",
    "yhat = MLP_classification_predict(w, Xtest, nHidden, np.max(y))\n",
    "print(f'Test error with final model = {np.sum([yhat[i]!=ytest[i] for i in range(len(ytest))])/len(ytest):.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdeca37-2acd-4101-b3c7-c942fae23f22",
   "metadata": {},
   "source": [
    "**<span style=\"font-size:18pt\">每层hidden layer的权重矩阵都加上bias项</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bcd820f-c264-4afc-aa9b-f0867eaf38ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration = 0,f=24539.31,validation error = 90.10%\n",
      "Training iteration = 1000,f=11010.37,validation error = 75.32%\n",
      "Training iteration = 2000,f=9584.84,validation error = 66.64%\n",
      "Training iteration = 3000,f=8317.63,validation error = 57.16%\n",
      "Training iteration = 4000,f=7530.31,validation error = 50.92%\n",
      "Training iteration = 5000,f=6917.88,validation error = 46.44%\n",
      "Training iteration = 6000,f=6430.75,validation error = 42.40%\n",
      "Training iteration = 7000,f=5964.39,validation error = 37.92%\n",
      "Training iteration = 8000,f=5693.78,validation error = 35.74%\n",
      "Training iteration = 9000,f=5393.90,validation error = 33.48%\n",
      "Training iteration = 10000,f=5028.75,validation error = 31.28%\n",
      "Training iteration = 11000,f=4840.75,validation error = 30.28%\n",
      "Training iteration = 12000,f=4788.93,validation error = 30.34%\n",
      "Training iteration = 13000,f=4694.95,validation error = 29.76%\n",
      "Training iteration = 14000,f=4531.84,validation error = 28.18%\n",
      "Training iteration = 15000,f=4426.74,validation error = 28.00%\n",
      "Training iteration = 16000,f=4302.84,validation error = 27.54%\n",
      "Training iteration = 17000,f=4040.20,validation error = 24.76%\n",
      "Training iteration = 18000,f=4028.94,validation error = 25.40%\n",
      "Training iteration = 19000,f=4153.55,validation error = 25.74%\n",
      "Test error with final model = 22.50%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import copy\n",
    "\n",
    "# Load data\n",
    "data = loadmat('/Users/lvangge/Desktop/Archive/project1_release/codes/digits.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "nLabels = max(y)[0]\n",
    "Xvalid = data['Xvalid']\n",
    "Xtest = data['Xtest']\n",
    "yvalid = data['yvalid']\n",
    "ytest = data['ytest']\n",
    "\n",
    "# Function to expand y to binary matrix\n",
    "def linearInd2Binary(ind, nLabels):\n",
    "    n = len(ind)\n",
    "    y = np.zeros((n, nLabels))\n",
    "    for i in range(n):\n",
    "        y[i, int(ind[i])-1] = 1\n",
    "    return y\n",
    "\n",
    "yExpanded = linearInd2Binary(y, nLabels)\n",
    "\n",
    "def sech(x):\n",
    "    return 2 / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, keepdims=True)\n",
    "\n",
    "# Standardize columns and add bias\n",
    "def standardize_cols(M, mu=None, sigma2=None):\n",
    "    M = M.astype(float)  # transform the matrix to float type\n",
    "    nrows, ncols = M.shape\n",
    "\n",
    "    if mu is None or sigma2 is None:\n",
    "        mu = np.mean(M, axis=0)\n",
    "        sigma2 = np.std(M, axis=0)\n",
    "        # handle the situation that sigma == 0\n",
    "        sigma2[sigma2 < np.finfo(float).eps] = 1\n",
    "\n",
    "    S = M - mu\n",
    "    if ncols > 0:\n",
    "        S = S / sigma2\n",
    "\n",
    "    return S, mu, sigma2\n",
    "\n",
    "def MLP_classification_loss(w, X, y, nHidden, nLabels, lam=0.5):\n",
    "    nInstances, nVars = X.shape  # the number of cases and character\n",
    "\n",
    "    # Form Weights\n",
    "    inputWeights = np.reshape(w[:nVars * nHidden[0]], (nVars, nHidden[0]))\n",
    "    offset = nVars * nHidden[0]\n",
    "    hiddenWeights = []\n",
    "    for h in range(2, len(nHidden) + 1):\n",
    "        hiddenWeights.append(np.reshape(w[offset:offset + (nHidden[h-2] + 1) * nHidden[h-1]], (nHidden[h-2] + 1, nHidden[h-1])))\n",
    "        offset += (nHidden[h-2] + 1) * nHidden[h-1]\n",
    "    outputWeights = np.reshape(w[offset:offset + (nHidden[-1] + 1) * nLabels], (nHidden[-1] + 1, nLabels))\n",
    "\n",
    "    # Loss function and gradient\n",
    "    f = 0\n",
    "    gInput = np.zeros_like(inputWeights)\n",
    "    gHidden = [np.zeros_like(hidden) for hidden in hiddenWeights]\n",
    "    gOutput = np.zeros_like(outputWeights)\n",
    "\n",
    "    # Compute Output\n",
    "    for i in range(nInstances):\n",
    "        ip = [np.dot(X[i], inputWeights)]\n",
    "        fp = [np.tanh(ip[0])]  # use tanh as activation function\n",
    "        for h in range(1, len(nHidden)):\n",
    "            ip.append(np.dot(np.hstack((fp[h-1], np.ones((1,)))), hiddenWeights[h-1]))\n",
    "            fp.append(np.tanh(ip[h]))\n",
    "        logits = np.dot(np.hstack((fp[-1], np.ones((1,)))), outputWeights)\n",
    "        probs = softmax(logits)\n",
    "\n",
    "        f += -np.dot(np.log(probs + 1e-10), y[i])\n",
    "\n",
    "        if gInput is not None:\n",
    "            err = probs - y[i]  # Gradient of the softmax output\n",
    "\n",
    "            # Output Weights\n",
    "            gOutput += np.outer(np.hstack((fp[-1], np.ones((1,)))), err)\n",
    "\n",
    "            if len(nHidden) > 1:\n",
    "                # Last Layer of Hidden Weights\n",
    "                backprop = np.dot(err, outputWeights[:-1, :].T) * (sech(ip[-1]) ** 2)\n",
    "                gHidden[-1] += np.outer(np.hstack((fp[-2], np.ones((1,)))), backprop)\n",
    "\n",
    "                # Other Hidden Layers\n",
    "                for h in range(len(nHidden) - 2, 0, -1):\n",
    "                    backprop = np.dot(backprop, hiddenWeights[h][:-1, :].T) * (sech(ip[h]) ** 2)\n",
    "                    gHidden[h-1] += np.outer(np.hstack((fp[h-1], np.ones((1,)))), backprop)\n",
    "\n",
    "                # Input Weights\n",
    "                backprop = np.dot(backprop, hiddenWeights[0][:-1, :].T) * (sech(ip[0]) ** 2)\n",
    "                gInput += np.outer(X[i], backprop)\n",
    "            else:\n",
    "                # Input Weights\n",
    "                gInput += np.outer(X[i], (sech(ip[-1]) ** 2) * np.dot(err, outputWeights[:-1, :].T))\n",
    "\n",
    "    # Put Gradient into vector\n",
    "    g = np.concatenate([gInput.flatten(), *[grad.flatten() for grad in gHidden], gOutput.flatten()])\n",
    "  \n",
    "    return f, g\n",
    "\n",
    "def MLP_classification_predict(w, X, nHidden, nLabels):\n",
    "    nInstances, nVars = X.shape\n",
    "\n",
    "    # Form Weights\n",
    "    inputWeights = np.reshape(w[:nVars * nHidden[0]], (nVars, nHidden[0]))\n",
    "    offset = nVars * nHidden[0]\n",
    "    hiddenWeights = []\n",
    "    for h in range(2, len(nHidden) + 1):\n",
    "        hiddenWeights.append(np.reshape(w[offset:offset + (nHidden[h-2] + 1) * nHidden[h-1]], (nHidden[h-2] + 1, nHidden[h-1])))\n",
    "        offset += (nHidden[h-2] + 1) * nHidden[h-1]\n",
    "    outputWeights = np.reshape(w[offset:offset + (nHidden[-1] + 1) * nLabels], (nHidden[-1] + 1, nLabels))\n",
    "\n",
    "    # Compute Output\n",
    "    y = np.zeros((nInstances, nLabels))\n",
    "    for i in range(nInstances):\n",
    "        ip = [np.dot(X[i], inputWeights)]\n",
    "        fp = [np.tanh(ip[0])]\n",
    "        for h in range(1, len(nHidden)):\n",
    "            ip.append(np.dot(np.hstack((fp[h-1], np.ones((1,)))), hiddenWeights[h-1]))\n",
    "            fp.append(np.tanh(ip[h]))\n",
    "        logits = np.dot(np.hstack((fp[-1], np.ones((1,)))), outputWeights)\n",
    "        y[i] = softmax(logits)\n",
    "\n",
    "    y = np.argmax(y, axis=1) + 1\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "X, mu, sigma = standardize_cols(X)\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X)) # add bias column\n",
    "\n",
    "Xvalid = standardize_cols(Xvalid, mu, sigma)[0]\n",
    "Xvalid = np.hstack((np.ones((Xvalid.shape[0], 1)), Xvalid))\n",
    "\n",
    "Xtest = standardize_cols(Xtest, mu, sigma)[0]\n",
    "Xtest = np.hstack((np.ones((Xtest.shape[0], 1)), Xtest))\n",
    "\n",
    "# Choose network structure\n",
    "nHidden = [50, 10, 10]\n",
    "\n",
    "# Initialize weights 'w'\n",
    "nParams = X.shape[1] * nHidden[0]\n",
    "for h in range(1, len(nHidden)):\n",
    "    nParams += (nHidden[h-1] + 1) * nHidden[h]\n",
    "nParams += (nHidden[-1] + 1) * np.max(y)\n",
    "w = np.random.randn(nParams)\n",
    "\n",
    "# Train with stochastic gradient descent\n",
    "maxIter = 20000\n",
    "stepSize = 1e-2\n",
    "momentum = 0.5\n",
    "w_history = [w]\n",
    "for iter in range(1, maxIter+1):\n",
    "    if (iter-1) % round(maxIter/20) == 0:\n",
    "        yhat = MLP_classification_predict(w, Xvalid, nHidden, np.max(y))\n",
    "        f = MLP_classification_loss(w, Xvalid, linearInd2Binary(yvalid,nLabels), nHidden, np.max(y))[0]\n",
    "        print(f'Training iteration = {iter-1},f={f:.2f},validation error = {np.sum(yhat != yvalid.reshape(Xvalid.shape[0]))/Xvalid.shape[0]:.2%}')\n",
    "    \n",
    "    i = np.random.randint(0, len(X))\n",
    "    X_i = X[i].reshape(1, -1)\n",
    "    yExpanded_i = yExpanded[i].reshape(1, -1)\n",
    "    f, g = MLP_classification_loss(w, X_i, yExpanded_i, nHidden, np.max(y))\n",
    "    w_history.append(w)\n",
    "    w = w - stepSize * g + momentum * (w - w_history[0])\n",
    "    w_history.pop(0)\n",
    "# Evaluate test error\n",
    "yhat = MLP_classification_predict(w, Xtest, nHidden, np.max(y))\n",
    "print(f'Test error with final model = {np.sum([yhat[i]!=ytest[i] for i in range(len(ytest))])/len(ytest):.2%}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d972054-5179-45b7-9afa-5f7108b5db0f",
   "metadata": {},
   "source": [
    "**<span style=\"font-size:18pt\">初步尝试使用卷积神经网络，固定初始卷积核</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6acde27c-2432-4197-87b6-b0c7323d7836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration = 0,f=53554.41,validation error = 90.20%\n",
      "Training iteration = 500,f=38506.91,validation error = 82.84%\n",
      "Training iteration = 1000,f=30928.80,validation error = 78.16%\n",
      "Training iteration = 1500,f=25753.62,validation error = 75.04%\n",
      "Training iteration = 2000,f=22126.41,validation error = 71.86%\n",
      "Training iteration = 2500,f=19516.39,validation error = 69.54%\n",
      "Training iteration = 3000,f=17202.92,validation error = 67.16%\n",
      "Training iteration = 3500,f=15785.80,validation error = 65.34%\n",
      "Training iteration = 4000,f=14635.28,validation error = 64.34%\n",
      "Training iteration = 4500,f=13567.71,validation error = 62.34%\n",
      "Training iteration = 5000,f=12723.28,validation error = 61.52%\n",
      "Training iteration = 5500,f=11897.73,validation error = 59.94%\n",
      "Training iteration = 6000,f=11319.22,validation error = 59.28%\n",
      "Training iteration = 6500,f=10670.23,validation error = 57.62%\n",
      "Training iteration = 7000,f=10294.86,validation error = 57.06%\n",
      "Training iteration = 7500,f=9975.01,validation error = 56.18%\n",
      "Training iteration = 8000,f=9607.04,validation error = 55.34%\n",
      "Training iteration = 8500,f=9312.35,validation error = 54.50%\n",
      "Training iteration = 9000,f=9119.26,validation error = 55.40%\n",
      "Training iteration = 9500,f=9018.29,validation error = 55.00%\n",
      "Test error with final model = 52.90%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import copy\n",
    "\n",
    "# Load data\n",
    "data = loadmat('/Users/lvangge/Desktop/Archive/project1_release/codes/digits.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "nLabels = max(y)[0]\n",
    "Xvalid = data['Xvalid']\n",
    "Xtest = data['Xtest']\n",
    "yvalid = data['yvalid']\n",
    "ytest = data['ytest']\n",
    "\n",
    "# Function to expand y to binary matrix\n",
    "def linearInd2Binary(ind, nLabels):\n",
    "    n = len(ind)\n",
    "    y = np.zeros((n, nLabels))\n",
    "    for i in range(n):\n",
    "        y[i, int(ind[i])-1] = 1\n",
    "    return y\n",
    "\n",
    "yExpanded = linearInd2Binary(y, nLabels)\n",
    "\n",
    "def sech(x):\n",
    "    return 2 / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, keepdims=True)\n",
    "\n",
    "def conv(X, K):\n",
    "    Y = np.zeros((X.shape[0]-K.shape[0]+1, X.shape[1]-K.shape[1]+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i][j] = np.sum(X[i:i+K.shape[0],j:j+K.shape[1]] * K)\n",
    "    return Y\n",
    "\n",
    "def pool(X, pool_shape, mode):\n",
    "    pa, pb = pool_shape\n",
    "    Y = np.zeros(X.shape[0] - pa + 1, X.shape[1] - pb +1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i][j] = np.max(X[i:i+pa, j:j+pb])\n",
    "            if mode == 'avg':\n",
    "                Y[i][j] = 1/(pa*pb) * np.sum(X[i:i+pa, j:j+pb])\n",
    "    \n",
    "    return Y\n",
    "\n",
    "# Standardize columns and add bias\n",
    "def standardize_cols(M, mu=None, sigma2=None):\n",
    "    M = M.astype(float)  # transform the matrix to float type\n",
    "    nrows, ncols = M.shape\n",
    "\n",
    "    if mu is None or sigma2 is None:\n",
    "        mu = np.mean(M, axis=0)\n",
    "        sigma2 = np.std(M, axis=0)\n",
    "        # handle the situation that sigma == 0\n",
    "        sigma2[sigma2 < np.finfo(float).eps] = 1\n",
    "\n",
    "    S = M - mu\n",
    "    if ncols > 0:\n",
    "        S = S / sigma2\n",
    "\n",
    "    return S, mu, sigma2\n",
    "\n",
    "def MLP_classification_loss(w, X, y, nHidden, nLabels, lam=0.5):\n",
    "    nInstances, nVars = X.shape  # the number of cases and character\n",
    "\n",
    "    # Form Weights\n",
    "    inputWeights = np.reshape(w[:nVars * nHidden[0]], (nVars, nHidden[0]))\n",
    "    offset = nVars * nHidden[0]\n",
    "    hiddenWeights = []\n",
    "    for h in range(2, len(nHidden) + 1):\n",
    "        hiddenWeights.append(np.reshape(w[offset:offset + (nHidden[h-2] + 1) * nHidden[h-1]], (nHidden[h-2] + 1, nHidden[h-1])))\n",
    "        offset += (nHidden[h-2] + 1) * nHidden[h-1]\n",
    "    outputWeights = np.reshape(w[offset:offset + (nHidden[-1] + 1) * nLabels], (nHidden[-1] + 1, nLabels))\n",
    "\n",
    "    # Loss function and gradient\n",
    "    f = 0\n",
    "    gInput = np.zeros_like(inputWeights)\n",
    "    gHidden = [np.zeros_like(hidden) for hidden in hiddenWeights]\n",
    "    gOutput = np.zeros_like(outputWeights)\n",
    "\n",
    "    # Compute Output\n",
    "    for i in range(nInstances):\n",
    "        ip = [np.dot(X[i], inputWeights)]\n",
    "        fp = [np.tanh(ip[0])]  # use tanh as activation function\n",
    "        for h in range(1, len(nHidden)):\n",
    "            ip.append(np.dot(np.hstack((fp[h-1], np.ones((1,)))), hiddenWeights[h-1]))\n",
    "            fp.append(np.tanh(ip[h]))\n",
    "        logits = np.dot(np.hstack((fp[-1], np.ones((1,)))), outputWeights)\n",
    "        probs = softmax(logits)\n",
    "\n",
    "        f += -np.dot(np.log(probs + 1e-10), y[i])\n",
    "\n",
    "        if gInput is not None:\n",
    "            err = probs - y[i]  # Gradient of the softmax output\n",
    "\n",
    "            # Output Weights\n",
    "            gOutput += np.outer(np.hstack((fp[-1], np.ones((1,)))), err)\n",
    "\n",
    "            if len(nHidden) > 1:\n",
    "                # Last Layer of Hidden Weights\n",
    "                backprop = np.dot(err, outputWeights[:-1, :].T) * (sech(ip[-1]) ** 2)\n",
    "                gHidden[-1] += np.outer(np.hstack((fp[-2], np.ones((1,)))), backprop)\n",
    "\n",
    "                # Other Hidden Layers\n",
    "                for h in range(len(nHidden) - 2, 0, -1):\n",
    "                    backprop = np.dot(backprop, hiddenWeights[h][:-1, :].T) * (sech(ip[h]) ** 2)\n",
    "                    gHidden[h-1] += np.outer(np.hstack((fp[h-1], np.ones((1,)))), backprop)\n",
    "\n",
    "                # Input Weights\n",
    "                backprop = np.dot(backprop, hiddenWeights[0][:-1, :].T) * (sech(ip[0]) ** 2)\n",
    "                gInput += np.outer(X[i], backprop)\n",
    "            else:\n",
    "                # Input Weights\n",
    "                gInput += np.outer(X[i], (sech(ip[-1]) ** 2) * np.dot(err, outputWeights[:-1, :].T))\n",
    "\n",
    "    # Put Gradient into vector\n",
    "    g = np.concatenate([gInput.flatten(), *[grad.flatten() for grad in gHidden], gOutput.flatten()])\n",
    "  \n",
    "    return f, g\n",
    "\n",
    "def MLP_classification_predict(w, X, nHidden, nLabels):\n",
    "    nInstances, nVars = X.shape\n",
    "\n",
    "    # Form Weights\n",
    "    inputWeights = np.reshape(w[:nVars * nHidden[0]], (nVars, nHidden[0]))\n",
    "    offset = nVars * nHidden[0]\n",
    "    hiddenWeights = []\n",
    "    for h in range(2, len(nHidden) + 1):\n",
    "        hiddenWeights.append(np.reshape(w[offset:offset + (nHidden[h-2] + 1) * nHidden[h-1]], (nHidden[h-2] + 1, nHidden[h-1])))\n",
    "        offset += (nHidden[h-2] + 1) * nHidden[h-1]\n",
    "    outputWeights = np.reshape(w[offset:offset + (nHidden[-1] + 1) * nLabels], (nHidden[-1] + 1, nLabels))\n",
    "\n",
    "    # Compute Output\n",
    "    y = np.zeros((nInstances, nLabels))\n",
    "    for i in range(nInstances):\n",
    "        ip = [np.dot(X[i], inputWeights)]\n",
    "        fp = [np.tanh(ip[0])]\n",
    "        for h in range(1, len(nHidden)):\n",
    "            ip.append(np.dot(np.hstack((fp[h-1], np.ones((1,)))), hiddenWeights[h-1]))\n",
    "            fp.append(np.tanh(ip[h]))\n",
    "        logits = np.dot(np.hstack((fp[-1], np.ones((1,)))), outputWeights)\n",
    "        y[i] = softmax(logits)\n",
    "\n",
    "    y = np.argmax(y, axis=1) + 1\n",
    "\n",
    "    return y\n",
    "\n",
    "# coventional layer\n",
    "conv_kernel = np.array([[-1, 0, -1],[0, 4 , 0],[-1, 0, -1]])\n",
    "X, mu, sigma = standardize_cols(X)\n",
    "X = np.array([conv(X.reshape(-1,16,16)[i] ,conv_kernel).flatten() for i in range(X.shape[0])])\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X)) # add bias column\n",
    "\n",
    "Xvalid = standardize_cols(Xvalid, mu, sigma)[0]\n",
    "Xvalid = np.array([conv(Xvalid.reshape(-1,16,16)[i],conv_kernel).flatten() for i in range(Xvalid.shape[0])])\n",
    "Xvalid = np.hstack((np.ones((Xvalid.shape[0], 1)), Xvalid))\n",
    "\n",
    "Xtest = standardize_cols(Xtest, mu, sigma)[0]\n",
    "Xtest = np.array([conv(Xtest.reshape(-1,16,16)[i],conv_kernel).flatten() for i in range(Xtest.shape[0])])\n",
    "Xtest = np.hstack((np.ones((Xtest.shape[0], 1)), Xtest))\n",
    "\n",
    "# Choose network structure\n",
    "nHidden = [50]\n",
    "\n",
    "# Initialize weights 'w'\n",
    "nParams = X.shape[1] * nHidden[0]\n",
    "for h in range(1, len(nHidden)):\n",
    "    nParams += (nHidden[h-1] + 1) * nHidden[h]\n",
    "nParams += (nHidden[-1] + 1) * np.max(y)\n",
    "w = np.random.randn(nParams)\n",
    "\n",
    "# Train with stochastic gradient descent\n",
    "maxIter = 10000\n",
    "stepSize = 1e-3\n",
    "momentum = 0.9\n",
    "w_history = [w]\n",
    "for iter in range(1, maxIter+1):\n",
    "    if (iter-1) % round(maxIter/20) == 0:\n",
    "        yhat = MLP_classification_predict(w, Xvalid, nHidden, np.max(y))\n",
    "        f = MLP_classification_loss(w, Xvalid, linearInd2Binary(yvalid,nLabels), nHidden, np.max(y))[0]\n",
    "        print(f'Training iteration = {iter-1},f={f:.2f},validation error = {np.sum(yhat != yvalid.reshape(Xvalid.shape[0]))/Xvalid.shape[0]:.2%}')\n",
    "    \n",
    "    i = np.random.randint(0, len(X))\n",
    "    X_i = X[i].reshape(1, -1)\n",
    "    yExpanded_i = yExpanded[i].reshape(1, -1)\n",
    "    f, g = MLP_classification_loss(w, X_i, yExpanded_i, nHidden, np.max(y))\n",
    "    w_history.append(w)\n",
    "    w = w - stepSize * g + momentum * (w - w_history[0])\n",
    "    w_history.pop(0)\n",
    "# Evaluate test error\n",
    "yhat = MLP_classification_predict(w, Xtest, nHidden, np.max(y))\n",
    "print(f'Test error with final model = {np.sum([yhat[i]!=ytest[i] for i in range(len(ytest))])/len(ytest):.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5319a0-8456-4fdb-b697-ece6f26ccbac",
   "metadata": {},
   "source": [
    "**<span style=\"font-size:18pt\">尝试用torch实现cnn</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f907a363-6394-4c20-a9cf-52da27b0d99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train_err:80.1%, train_loss:2.284, valid_err:74.9%, valid_loss:2.262\n",
      "Epoch: 2, train_err:70.8%, train_loss:2.229, valid_err:65.9%, valid_loss:2.190\n",
      "Epoch: 3, train_err:64.7%, train_loss:2.121, valid_err:64.0%, valid_loss:2.041\n",
      "Epoch: 4, train_err:54.3%, train_loss:1.861, valid_err:42.9%, valid_loss:1.642\n",
      "Epoch: 5, train_err:33.4%, train_loss:1.268, valid_err:34.6%, valid_loss:1.002\n",
      "Epoch: 6, train_err:20.3%, train_loss:0.739, valid_err:23.7%, valid_loss:0.709\n",
      "Epoch: 7, train_err:14.4%, train_loss:0.511, valid_err:20.1%, valid_loss:0.603\n",
      "Epoch: 8, train_err:10.7%, train_loss:0.380, valid_err:9.6%, valid_loss:0.349\n",
      "Epoch: 9, train_err:8.3%, train_loss:0.306, valid_err:8.9%, valid_loss:0.317\n",
      "Epoch:10, train_err:7.3%, train_loss:0.258, valid_err:7.8%, valid_loss:0.267\n",
      "Traing done\n",
      "Test_err:7.6%, test_loss:0.249\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cnn model for the pj\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data set\n",
    "data = loadmat('/Users/lvangge/Desktop/Archive/project1_release/codes/digits.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "nLabels = max(y)[0]\n",
    "Xvalid = data['Xvalid']\n",
    "Xtest = data['Xtest']\n",
    "yvalid = data['yvalid']\n",
    "ytest = data['ytest']\n",
    "\n",
    "# Standardize columns and add bias\n",
    "def standardize_cols(M, mu=None, sigma2=None):\n",
    "    M = M.astype(float)  # transform the matrix to float type\n",
    "    nrows, ncols = M.shape\n",
    "\n",
    "    if mu is None or sigma2 is None:\n",
    "        mu = np.mean(M, axis=0)\n",
    "        sigma2 = np.std(M, axis=0)\n",
    "        # handle the situation that sigma == 0\n",
    "        sigma2[sigma2 < np.finfo(float).eps] = 1\n",
    "\n",
    "    S = M - mu\n",
    "    if ncols > 0:\n",
    "        S = S / sigma2\n",
    "\n",
    "    return S, mu, sigma2\n",
    "\n",
    "X, mu, sigma = standardize_cols(X)\n",
    "# X = np.hstack((np.ones((X.shape[0], 1)), X)) # add bias column\n",
    "\n",
    "Xvalid = standardize_cols(Xvalid, mu, sigma)[0]\n",
    "# Xvalid = np.hstack((np.ones((Xvalid.shape[0], 1)), Xvalid))\n",
    "\n",
    "Xtest = standardize_cols(Xtest, mu, sigma)[0]\n",
    "# Xtest = np.hstack((np.ones((Xtest.shape[0], 1)), Xtest))\n",
    "\n",
    "# Change the shape of data\n",
    "X = X.reshape(-1, 1, 16, 16)\n",
    "Xvalid = Xvalid.reshape(-1, 1, 16, 16)\n",
    "Xtest = Xtest.reshape(-1, 1, 16, 16)\n",
    "\n",
    "# Function to expand y to binary matrix\n",
    "def linearInd2Binary(ind, nLabels):\n",
    "    n = len(ind)\n",
    "    y = np.zeros((n, nLabels))\n",
    "    for i in range(n):\n",
    "        y[i, int(ind[i])-1] = 1\n",
    "    return y\n",
    "\n",
    "# Trandform data to dataloader\n",
    "y = linearInd2Binary(y,nLabels)\n",
    "yvalid= linearInd2Binary(yvalid,nLabels)\n",
    "ytest = linearInd2Binary(ytest,nLabels)\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X,dtype=torch.float32), torch.tensor(y, dtype=torch.float32))\n",
    "valid_dataset = TensorDataset(torch.tensor(Xvalid,dtype=torch.float32), torch.tensor(yvalid, dtype=torch.float32))\n",
    "test_dataset = TensorDataset(torch.tensor(Xtest, dtype=torch.float32), torch.tensor(ytest,dtype=torch.float32))\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=64, shuffle=True)\n",
    "test_dl = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define train achitecture\n",
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 64)\n",
    "        self.fc2 = nn.Linear(64, nLabels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "model = Model()\n",
    "\n",
    "# Define loss function, learning rate and optimizer\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "learn_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learn_rate)\n",
    "\n",
    "# Training loop\n",
    "def train(dataloader, model, loss_func, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, train_err = 0, 0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        pred = model(X)\n",
    "        loss = loss_func(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_err += (torch.argmax(F.softmax(pred, dim=1), dim=1) != torch.argmax(y, dim=1)).type(torch.float).sum().item()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    train_err /= size\n",
    "\n",
    "    return train_loss, train_err\n",
    "\n",
    "# Test-Valid loop\n",
    "def test(dataloader, model, loss_func):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, test_err = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            loss = loss_func(pred, y)\n",
    "            test_err += (torch.argmax(F.softmax(pred, dim=1), dim=1) != torch.argmax(y, dim=1)).type(torch.float).sum().item()\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    test_err /= size\n",
    "    \n",
    "    return test_loss, test_err\n",
    "\n",
    "# Main training and evaluating loop\n",
    "if __name__ == '__main__':\n",
    "    epochs = 10\n",
    "    train_loss = []\n",
    "    train_err = []\n",
    "    valid_loss = []\n",
    "    valid_err = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss, epoch_train_err = train(train_dl, model, loss_func, optimizer)\n",
    "\n",
    "        model.eval()\n",
    "        epoch_valid_loss, epoch_valid_err = test(valid_dl, model, loss_func)\n",
    "\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        train_err.append(epoch_train_err)\n",
    "        valid_loss.append(epoch_valid_loss)\n",
    "        valid_err.append(epoch_valid_err)\n",
    "\n",
    "        template = ('Epoch:{:2d}, train_err:{:.1f}%, train_loss:{:.3f}, valid_err:{:.1f}%, valid_loss:{:.3f}')\n",
    "        print(template.format(epoch + 1, epoch_train_err*100, epoch_train_loss, epoch_valid_err*100, epoch_valid_loss))\n",
    "\n",
    "    print(\"Traing done\")\n",
    "\n",
    "    test_loss, test_err = test(test_dl, model, loss_func)\n",
    "    print(('Test_err:{:.1f}%, test_loss:{:.3f}').format(test_err*100, test_loss))\n",
    "\n",
    "def show_plot():\n",
    "    epoch_range = range(epochs)\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epoch_range, train_loss, label='Train Loss')\n",
    "    plt.plot(epoch_range, valid_loss, label='Valid Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Train and Valid Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epoch_range, train_err, label='Train Error')\n",
    "    plt.plot(epoch_range, valid_err, label='Valid Error')\n",
    "    plt.legend()\n",
    "    plt.title('Train and Valid Error')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed7af8-bebf-4ec7-ada2-df71390f7864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
